import tensorflow as tf
from tensorflow.keras import layers
import numpy as np

class GraphConvLayer(layers.Layer):
    def __init__(self, units, adjacency_matrix):
        super(GraphConvLayer, self).__init__()
        self.units = units
        self.adjacency_matrix = tf.Variable(adjacency_matrix, dtype=tf.float32, trainable=False)
        self.batch_norm = layers.BatchNormalization()  # ë°°ì¹˜ ì •ê·œí™” ì¶”ê°€

    def build(self, input_shape):
        # input_shape: (batch*frames, joints, features)
        self.kernel = self.add_weight(
            shape=(input_shape[-1], self.units),
            initializer="glorot_uniform",
            trainable=True
        )

    def call(self, inputs):
        # inputs: (batch*frames, joints, features)
        x = tf.linalg.matmul(self.adjacency_matrix, inputs)  # Graph convolution
        x = tf.linalg.matmul(x, self.kernel)  # Apply learnable weights
        x = self.batch_norm(x)  # Batch normalization
        x = tf.nn.leaky_relu(x)  # Activation function applied AFTER batch norm
        return x

# âœ… ST-GCN ëª¨ë¸ ì •ì˜
@tf.keras.utils.register_keras_serializable()
class STGCN(tf.keras.Model):
    def __init__(self, num_joints, num_features, adjacency_matrix, num_classes, **kwargs):
        super(STGCN, self).__init__(**kwargs)

        self.num_joints = num_joints
        self.num_features = num_features
        self.num_classes = num_classes
        self.adjacency_matrix = tf.convert_to_tensor(adjacency_matrix, dtype=tf.float32)  # í…ì„œë¡œ ë³€í™˜
        
        self.graph_conv1 = GraphConvLayer(64, adjacency_matrix)
        self.graph_conv2 = GraphConvLayer(128, adjacency_matrix)
        self.graph_conv3 = GraphConvLayer(256, adjacency_matrix)  # ì¶”ê°€ëœ Graph Conv
        self.graph_conv4 = GraphConvLayer(512, adjacency_matrix)  # ì¶”ê°€ëœ Graph Conv
        
        self.temporal_conv1 = layers.Conv1D(512, kernel_size=7, padding="same")
        self.temporal_conv2 = layers.Conv1D(256, kernel_size=7, padding="same")
        self.temporal_conv3 = layers.Conv1D(128, kernel_size=5, padding="same")
        self.temporal_conv4 = layers.Conv1D(64, kernel_size=3, padding="same")
        
        self.batch_norm1 = layers.BatchNormalization()
        self.batch_norm2 = layers.BatchNormalization()
        self.batch_norm3 = layers.BatchNormalization()
        self.batch_norm4 = layers.BatchNormalization()
        
        self.activation = layers.Activation("relu")
        self.global_pool = layers.GlobalAveragePooling1D()
        self.fc = layers.Dense(num_classes, activation="softmax", kernel_regularizer=tf.keras.regularizers.l2(0.1))
        self.dropout = layers.Dropout(0.5) 

    def build(self, input_shape):
        super().build(input_shape)

    def call(self, inputs):
        # âœ… ì…ë ¥ ì²˜ë¦¬: (batch, frames, views, joints, features)
        if len(inputs.shape) == 5:
            # ì—¬ëŸ¬ ê°ë„(View) ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° í‰ê·  ë‚´ê¸°
            inputs = tf.reduce_mean(inputs, axis=2)  # (batch, frames, joints, features)
        
        batch_size = tf.shape(inputs)[0]
        frames = tf.shape(inputs)[1]
        joints = tf.shape(inputs)[2]
        features = tf.shape(inputs)[3]
        x = tf.reshape(inputs, (batch_size * frames, joints, features))  # (batch * joints, frames, features)
        
        # âœ… ëª¨ë¸ ì²˜ë¦¬
        x = self.graph_conv1(x)
        x = self.batch_norm1(x)
        x = self.activation(x)
        
        x = self.graph_conv2(x)
        x = self.batch_norm2(x)
        x = self.activation(x)

        x = self.graph_conv3(x)
        x = self.batch_norm3(x)
        x = self.activation(x)

        x = self.graph_conv4(x)
        x = self.batch_norm4(x)
        x = self.activation(x)

        # Temporal Convë¥¼ ìœ„í•´ í”„ë ˆì„ë³„ë¡œ ëª¨ë“  ê´€ì ˆì˜ ì •ë³´ë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ê²°í•©
        out_features = tf.shape(x)[-1]
        x = tf.reshape(x, (batch_size, frames, joints * out_features))

        x = self.temporal_conv1(x)
        x = self.temporal_conv2(x)
        x = self.temporal_conv3(x)
        x = self.temporal_conv4(x)

        # frames ì°¨ì›ì„ í‰ê·  ë‚´ì–´ ìµœì¢… íŠ¹ì§• ë²¡í„° ìƒì„±
        x = self.global_pool(x)
        x = self.dropout(x)
        
        return self.fc(x)

    def get_config(self):
        config = super(STGCN, self).get_config()
        config.update({
            "num_joints": self.num_joints,
            "num_features": self.num_features,
            "adjacency_matrix": self.adjacency_matrix.numpy().tolist(),  # âœ… ë³€ê²½: numpy() ì‚¬ìš©
            "num_classes": self.num_classes,
            "name": self.name  # ğŸ‘ˆ ì¶”ê°€
        })
        return config


    @classmethod
    def from_config(cls, config):
        import numpy as np
        config["adjacency_matrix"] = np.array(config["adjacency_matrix"])  # ë¦¬ìŠ¤íŠ¸ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
        return cls(**config)