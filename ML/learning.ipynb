{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "463ae2ff-2580-4da6-9a54-d3b05bb44c7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "[0, 2, 5, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 21, 23, 25, 26, 28, 30, 31, 32]\n",
    "keypoints = [\n",
    "    \"Point_0\", \"Point_2\", \"Point_5\", \"Point_7\", \"Point_8\", \"Point_11\", \n",
    "    \"Point_12\", \"Point_13\", \"Point_14\", \"Point_15\", \"Point_16\", \"Point_17\", \n",
    "    \"Point_18\", \"Point_21\", \"Point_23\", \"Point_25\", \"Point_26\", \"Point_28\", \n",
    "    \"Point_30\", \"Point_31\", \"Point_32\"\n",
    "]\n",
    "\n",
    "\n",
    "# JSON 데이터 로드 함수\n",
    "def load_json_skeleton_view1(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    num_frames = len(data[\"frames\"])\n",
    "    num_joints = len(keypoints)\n",
    "    num_features = 2  # (x, y)\n",
    "    num_views = 1     \n",
    "\n",
    "    # ✅ (1, 프레임, 뷰, 관절, 좌표) 형태로 데이터 배열 생성\n",
    "    X_data = np.zeros((1, num_frames, num_views, num_joints, num_features), dtype=np.float32)\n",
    "\n",
    "    views = [\"view1\"]\n",
    "\n",
    "    # ✅ JSON 데이터 -> 배열 변환\n",
    "    for frame_idx, frame in enumerate(data[\"frames\"]):\n",
    "        for view_idx, view in enumerate(views):\n",
    "            pts = frame.get(view, {}).get(\"pts\", {})\n",
    "            for joint_idx, joint_name in enumerate(keypoints):\n",
    "                if joint_name in pts:\n",
    "                    X_data[0, frame_idx, view_idx, joint_idx, 0] = pts[joint_name][\"x\"]\n",
    "                    X_data[0, frame_idx, view_idx, joint_idx, 1] = pts[joint_name][\"y\"]\n",
    "\n",
    "    return X_data, data.get(\"type_info\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b1c40f17-54a1-4684-a426-716833db587c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리된 데이터 Shape: (80, 32, 5, 21, 2)\n"
     ]
    }
   ],
   "source": [
    "# ✅ JSON 데이터 로드 함수 (5개 각도 전처리)\n",
    "def load_json_skeleton(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    num_frames = len(data[\"frames\"])\n",
    "    num_joints = len(keypoints)\n",
    "    num_features = 2  # (x, y)\n",
    "    num_views = 5     # view1 ~ view5\n",
    "\n",
    "    # ✅ (1, 프레임, 뷰, 관절, 좌표) 형태로 데이터 배열 생성\n",
    "    X_data = np.zeros((1, num_frames, num_views, num_joints, num_features), dtype=np.float32)\n",
    "\n",
    "    views = [\"view1\", \"view2\", \"view3\", \"view4\", \"view5\"]\n",
    "\n",
    "    # ✅ JSON 데이터 -> 배열 변환\n",
    "    for frame_idx, frame in enumerate(data[\"frames\"]):\n",
    "        for view_idx, view in enumerate(views):\n",
    "            pts = frame.get(view, {}).get(\"pts\", {})\n",
    "            for joint_idx, joint_name in enumerate(keypoints):\n",
    "                if joint_name in pts:\n",
    "                    X_data[0, frame_idx, view_idx, joint_idx, 0] = pts[joint_name][\"x\"]\n",
    "                    X_data[0, frame_idx, view_idx, joint_idx, 1] = pts[joint_name][\"y\"]\n",
    "\n",
    "    return X_data, data.get(\"type_info\", None)\n",
    "\n",
    "# ✅ 여러 개의 JSON 파일을 한 번에 로드하는 함수 (올바른/잘못된 데이터 포함)\n",
    "def load_labeled_json_skeleton(file_paths, labels):\n",
    "    X_data_list = []\n",
    "    y_data_list = []\n",
    "\n",
    "    for file_path, label in zip(file_paths, labels):\n",
    "        X, _ = load_json_skeleton(file_path)\n",
    "        X_data_list.append(X)\n",
    "        y_data_list.append(label)\n",
    "\n",
    "    # ✅ 여러 개의 파일을 하나의 NumPy 배열로 병합\n",
    "    X_train = np.concatenate(X_data_list, axis=0)  # (batch_size, frames, views, joints, features)\n",
    "    y_train = np.array(y_data_list)                # (batch_size, )\n",
    "\n",
    "    return X_train, y_train\n",
    "    \n",
    "# ✅ 올바른 자세와 잘못된 자세 데이터를 함께 로드\n",
    "file_paths = [\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-6-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-7-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-6-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-7-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body10-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body10-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body10-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body10-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body10-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body10-6-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body10-7-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body11-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body11-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body11-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body11-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body11-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body11-6-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body11-7-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body12-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body12-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body12-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body12-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body12-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body12-6-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body12-7-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body17-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body17-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body17-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body17-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body17-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-562.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-563.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-564.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-565.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-566.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-567.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-568.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-569.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-570.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-571.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-572.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-573.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-574.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-575.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-576.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-577.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-578.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-579.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-580.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-581.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-582.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-583.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-584.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-585.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-586.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-587.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-588.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-589.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-590.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-591.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-592.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-562.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-563.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-564.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-565.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-566.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-567.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-568.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-569.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-570.json\",\n",
    "]\n",
    "\n",
    "labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  # 0 = 올바른 자세, 1 = 잘못된 자세\n",
    "\n",
    "# ✅ 전처리 실행\n",
    "X_train, y_train = load_labeled_json_skeleton(file_paths, labels)\n",
    "# ✅ 전처리된 데이터 형태 확인\n",
    "print(\"전처리된 데이터 Shape:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "eb3eaa30-3fdb-4a25-ae7e-7692c4e52f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized adjacency matrix shape: (21, 21)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import mediapipe as mp\n",
    "\n",
    "# ✅ 인접 행렬 정규화 함수: self-loop 추가 및 D^(-1/2) A D^(-1/2) 적용\n",
    "def normalize_adjacency_matrix(adj):\n",
    "    # 자기 루프 추가\n",
    "    np.fill_diagonal(adj, 1)\n",
    "    # Degree matrix 계산\n",
    "    degree = np.sum(adj, axis=1)\n",
    "    # 0 나누기 방지\n",
    "    degree[degree == 0] = 1\n",
    "    D_inv_sqrt = np.diag(1.0 / np.sqrt(degree))\n",
    "    # 정규화된 인접 행렬 계산: D^(-1/2) A D^(-1/2)\n",
    "    A_norm = D_inv_sqrt @ adj @ D_inv_sqrt\n",
    "    return A_norm\n",
    "    \n",
    "# ✅ 그래프 컨볼루션 레이어 정의\n",
    "class GraphConvLayer(layers.Layer):\n",
    "    def __init__(self, units, adjacency_matrix):\n",
    "        super(GraphConvLayer, self).__init__()\n",
    "        self.units = units\n",
    "        self.adjacency_matrix = tf.Variable(adjacency_matrix, dtype=tf.float32, trainable=False)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_shape: (batch*frames, joints, features)\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs: (batch*frames, joints, features)\n",
    "        x = tf.linalg.matmul(self.adjacency_matrix, inputs)\n",
    "        x = tf.linalg.matmul(x, self.kernel)  # 가중치 적용\n",
    "        return tf.nn.leaky_relu(x)  # 활성화 함수 적용\n",
    "\n",
    "# ✅ ST-GCN 모델 정의\n",
    "class STGCN(tf.keras.Model):\n",
    "    def __init__(self, num_joints, num_features, adjacency_matrix, num_classes):\n",
    "        super(STGCN, self).__init__()\n",
    "        self.graph_conv1 = GraphConvLayer(64, adjacency_matrix)\n",
    "        self.graph_conv2 = GraphConvLayer(128, adjacency_matrix)\n",
    "        self.graph_conv3 = GraphConvLayer(256, adjacency_matrix)  # 추가된 Graph Conv\n",
    "        self.graph_conv4 = GraphConvLayer(512, adjacency_matrix)  # 추가된 Graph Conv\n",
    "        self.temporal_conv1 = layers.Conv1D(512, kernel_size=5, padding=\"same\")\n",
    "        self.temporal_conv2 = layers.Conv1D(256, kernel_size=7, padding=\"same\")\n",
    "        self.temporal_conv3 = layers.Conv1D(128, kernel_size=7, padding=\"same\")\n",
    "        self.temporal_conv4 = layers.Conv1D(64, kernel_size=5, padding=\"same\")\n",
    "        self.batch_norm1 = layers.BatchNormalization()\n",
    "        self.batch_norm2 = layers.BatchNormalization()\n",
    "        self.batch_norm3 = layers.BatchNormalization()\n",
    "        self.batch_norm4 = layers.BatchNormalization()\n",
    "        self.activation = layers.Activation(\"relu\")\n",
    "        self.global_pool = layers.GlobalAveragePooling1D()\n",
    "        self.fc = layers.Dense(num_classes, activation=\"softmax\")\n",
    "        self.dropout = layers.Dropout(0.5) \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # ✅ 입력 처리: (batch, frames, views, joints, features)\n",
    "        if len(inputs.shape) == 5:\n",
    "            # 여러 각도(View) 데이터가 있는 경우 평균 내기\n",
    "            inputs = tf.reduce_mean(inputs, axis=2)  # (batch, frames, joints, features)\n",
    "        \n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        frames = tf.shape(inputs)[1]\n",
    "        joints = tf.shape(inputs)[2]\n",
    "        features = tf.shape(inputs)[3]\n",
    "        \n",
    "        x = tf.reshape(inputs, (batch_size * frames, joints, features))  # (batch * joints, frames, features)\n",
    "        \n",
    "        # ✅ 모델 처리\n",
    "        x = self.graph_conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.graph_conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        x = self.graph_conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        x = self.graph_conv4(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # x의 shape: (batch*frames, joints, out_features)\n",
    "        # Temporal Conv를 위해 프레임별로 모든 관절의 정보를 하나의 벡터로 결합\n",
    "        out_features = tf.shape(x)[-1]\n",
    "        x = tf.reshape(x, (batch_size, frames, joints * out_features))\n",
    "\n",
    "        x = self.temporal_conv1(x)\n",
    "        x = self.temporal_conv2(x)\n",
    "        x = self.temporal_conv3(x)\n",
    "        x = self.temporal_conv4(x)\n",
    "\n",
    "        # x = self.flatten(x)\n",
    "\n",
    "        # frames 차원을 평균 내어 최종 특징 벡터 생성\n",
    "        x = self.global_pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return self.fc(x)\n",
    "\n",
    "# Mediapipe에서 제공하는 POSE_CONNECTIONS을 활용\n",
    "mp_pose = mp.solutions.pose\n",
    "connections = list(mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "# ✅ 현재 선택된 19개 관절 인덱스 (사용자가 선택한 관절 리스트)\n",
    "selected_joints = [0, 2, 5, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 21, 23, 25, 26, 28, 30, 31, 32]\n",
    "\n",
    "# ✅ 원본 33개 관절을 기반으로 한 인접 행렬 생성\n",
    "full_adjacency_matrix = np.zeros((33, 33))  # 전체 33개 관절을 사용한 경우\n",
    "for joint1, joint2 in connections:\n",
    "    full_adjacency_matrix[joint1, joint2] = 1\n",
    "    full_adjacency_matrix[joint2, joint1] = 1  # 대칭 관계\n",
    "\n",
    "# ✅ 선택된 관절만을 포함하는 인접 행렬 생성\n",
    "num_joints = len(selected_joints)\n",
    "adjacency_matrix = np.zeros((num_joints, num_joints))\n",
    "\n",
    "for i, joint1 in enumerate(selected_joints):\n",
    "    for j, joint2 in enumerate(selected_joints):\n",
    "        adjacency_matrix[i, j] = full_adjacency_matrix[joint1, joint2]  # 기존 인접 행렬에서 추출\n",
    "\n",
    "# 인접 행렬 정규화 (자기 루프 추가 및 정규화)\n",
    "adjacency_matrix_norm = normalize_adjacency_matrix(adjacency_matrix)\n",
    "print(f\"Normalized adjacency matrix shape: {adjacency_matrix_norm.shape}\")\n",
    "\n",
    "num_features = 2\n",
    "num_classes = 2  # (올바른 자세 / 잘못된 자세)\n",
    "\n",
    "# ✅ ST-GCN 모델 생성 및 컴파일\n",
    "del stgcn_model\n",
    "stgcn_model = STGCN(num_joints, num_features, adjacency_matrix_norm, num_classes)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=0.0001,\n",
    "    decay_steps=2000,\n",
    "    alpha=0.00001\n",
    ")\n",
    "\n",
    "stgcn_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), \n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "5725513f-47a7-48ec-bfb8-265738ac83ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 클래스별 샘플 개수: {0.0: 64, 1.0: 64}\n",
      "X_train min after scaling: -0.07021019607782364\n",
      "X_train max after scaling: 0.8629935383796692\n",
      "X_train mean after scaling: 0.5254637002944946\n",
      "X_train std after scaling: 0.12587009370326996\n",
      "Epoch 1/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.5469 - loss: 0.6913 - val_accuracy: 0.3125 - val_loss: 2.4643\n",
      "Epoch 2/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 1.6285 - val_accuracy: 0.3125 - val_loss: 0.9842\n",
      "Epoch 3/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.7583 - val_accuracy: 0.6875 - val_loss: 0.6191\n",
      "Epoch 4/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4531 - loss: 0.8000 - val_accuracy: 0.6875 - val_loss: 0.6242\n",
      "Epoch 5/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4531 - loss: 0.8607 - val_accuracy: 0.6875 - val_loss: 0.6294\n",
      "Epoch 6/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4531 - loss: 0.7442 - val_accuracy: 0.3125 - val_loss: 0.7711\n",
      "Epoch 7/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6912 - val_accuracy: 0.3125 - val_loss: 1.0215\n",
      "Epoch 8/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5469 - loss: 0.7750 - val_accuracy: 0.3125 - val_loss: 1.0508\n",
      "Epoch 9/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.7884 - val_accuracy: 0.3125 - val_loss: 0.9190\n",
      "Epoch 10/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.7324 - val_accuracy: 0.3125 - val_loss: 0.7761\n",
      "Epoch 11/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6919 - val_accuracy: 0.6875 - val_loss: 0.6881\n",
      "Epoch 12/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4531 - loss: 0.6934 - val_accuracy: 0.6875 - val_loss: 0.6504\n",
      "Epoch 13/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4531 - loss: 0.7135 - val_accuracy: 0.6875 - val_loss: 0.6403\n",
      "Epoch 14/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4531 - loss: 0.7246 - val_accuracy: 0.6875 - val_loss: 0.6444\n",
      "Epoch 15/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4531 - loss: 0.7195 - val_accuracy: 0.6875 - val_loss: 0.6598\n",
      "Epoch 16/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4531 - loss: 0.7059 - val_accuracy: 0.6875 - val_loss: 0.6863\n",
      "Epoch 17/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4531 - loss: 0.6937 - val_accuracy: 0.3125 - val_loss: 0.7215\n",
      "Epoch 18/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6882 - val_accuracy: 0.3125 - val_loss: 0.7595\n",
      "Epoch 19/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6895 - val_accuracy: 0.3125 - val_loss: 0.7924\n",
      "Epoch 20/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6945 - val_accuracy: 0.3125 - val_loss: 0.8128\n",
      "Epoch 21/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6988 - val_accuracy: 0.3125 - val_loss: 0.8171\n",
      "Epoch 22/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6997 - val_accuracy: 0.3125 - val_loss: 0.8069\n",
      "Epoch 23/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6973 - val_accuracy: 0.3125 - val_loss: 0.7876\n",
      "Epoch 24/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6933 - val_accuracy: 0.3125 - val_loss: 0.7649\n",
      "Epoch 25/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6897 - val_accuracy: 0.3125 - val_loss: 0.7431\n",
      "Epoch 26/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6877 - val_accuracy: 0.3125 - val_loss: 0.7245\n",
      "Epoch 27/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6873 - val_accuracy: 0.3125 - val_loss: 0.7103\n",
      "Epoch 28/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6881 - val_accuracy: 0.3125 - val_loss: 0.7005\n",
      "Epoch 29/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6893 - val_accuracy: 0.3750 - val_loss: 0.6949\n",
      "Epoch 30/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5938 - loss: 0.6902 - val_accuracy: 0.4375 - val_loss: 0.6928\n",
      "Epoch 31/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6562 - loss: 0.6904 - val_accuracy: 0.3750 - val_loss: 0.6938\n",
      "Epoch 32/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6094 - loss: 0.6900 - val_accuracy: 0.3750 - val_loss: 0.6973\n",
      "Epoch 33/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6891 - val_accuracy: 0.3125 - val_loss: 0.7029\n",
      "Epoch 34/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6879 - val_accuracy: 0.3125 - val_loss: 0.7100\n",
      "Epoch 35/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6867 - val_accuracy: 0.3125 - val_loss: 0.7180\n",
      "Epoch 36/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6858 - val_accuracy: 0.3125 - val_loss: 0.7264\n",
      "Epoch 37/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6852 - val_accuracy: 0.3125 - val_loss: 0.7345\n",
      "Epoch 38/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6850 - val_accuracy: 0.3125 - val_loss: 0.7415\n",
      "Epoch 39/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6849 - val_accuracy: 0.3125 - val_loss: 0.7468\n",
      "Epoch 40/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6848 - val_accuracy: 0.3125 - val_loss: 0.7498\n",
      "Epoch 41/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6847 - val_accuracy: 0.3125 - val_loss: 0.7500\n",
      "Epoch 42/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6842 - val_accuracy: 0.3125 - val_loss: 0.7475\n",
      "Epoch 43/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6835 - val_accuracy: 0.3125 - val_loss: 0.7426\n",
      "Epoch 44/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6826 - val_accuracy: 0.3125 - val_loss: 0.7360\n",
      "Epoch 45/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6817 - val_accuracy: 0.3125 - val_loss: 0.7285\n",
      "Epoch 46/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6809 - val_accuracy: 0.3125 - val_loss: 0.7209\n",
      "Epoch 47/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6802 - val_accuracy: 0.3750 - val_loss: 0.7144\n",
      "Epoch 48/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6796 - val_accuracy: 0.3750 - val_loss: 0.7101\n",
      "Epoch 49/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6788 - val_accuracy: 0.3125 - val_loss: 0.7087\n",
      "Epoch 50/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6777 - val_accuracy: 0.3125 - val_loss: 0.7104\n",
      "Epoch 51/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6763 - val_accuracy: 0.3750 - val_loss: 0.7150\n",
      "Epoch 52/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6745 - val_accuracy: 0.3750 - val_loss: 0.7214\n",
      "Epoch 53/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6727 - val_accuracy: 0.3750 - val_loss: 0.7277\n",
      "Epoch 54/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6709 - val_accuracy: 0.3750 - val_loss: 0.7312\n",
      "Epoch 55/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6689 - val_accuracy: 0.3750 - val_loss: 0.7295\n",
      "Epoch 56/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6665 - val_accuracy: 0.3750 - val_loss: 0.7216\n",
      "Epoch 57/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5781 - loss: 0.6634 - val_accuracy: 0.3750 - val_loss: 0.7100\n",
      "Epoch 58/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5938 - loss: 0.6602 - val_accuracy: 0.3750 - val_loss: 0.7006\n",
      "Epoch 59/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6562 - loss: 0.6567 - val_accuracy: 0.4375 - val_loss: 0.6996\n",
      "Epoch 60/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6562 - loss: 0.6522 - val_accuracy: 0.3750 - val_loss: 0.7076\n",
      "Epoch 61/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6406 - loss: 0.6469 - val_accuracy: 0.3750 - val_loss: 0.7156\n",
      "Epoch 62/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6406 - loss: 0.6414 - val_accuracy: 0.4375 - val_loss: 0.7076\n",
      "Epoch 63/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6562 - loss: 0.6345 - val_accuracy: 0.5625 - val_loss: 0.6870\n",
      "Epoch 64/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7344 - loss: 0.6272 - val_accuracy: 0.5625 - val_loss: 0.6864\n",
      "Epoch 65/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7500 - loss: 0.6183 - val_accuracy: 0.4375 - val_loss: 0.7034\n",
      "Epoch 66/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7188 - loss: 0.6087 - val_accuracy: 0.5625 - val_loss: 0.6795\n",
      "Epoch 67/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7656 - loss: 0.5970 - val_accuracy: 0.5000 - val_loss: 0.6729\n",
      "Epoch 68/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.5843 - val_accuracy: 0.5625 - val_loss: 0.7016\n",
      "Epoch 69/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7656 - loss: 0.5716 - val_accuracy: 0.5625 - val_loss: 0.6297\n",
      "Epoch 70/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7344 - loss: 0.5648 - val_accuracy: 0.4375 - val_loss: 0.7783\n",
      "Epoch 71/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7188 - loss: 0.5644 - val_accuracy: 0.5625 - val_loss: 0.6366\n",
      "Epoch 72/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7500 - loss: 0.5373 - val_accuracy: 0.5000 - val_loss: 0.6623\n",
      "Epoch 73/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.5185 - val_accuracy: 0.5625 - val_loss: 0.7890\n",
      "Epoch 74/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7500 - loss: 0.5286 - val_accuracy: 0.6250 - val_loss: 0.6266\n",
      "Epoch 75/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6719 - loss: 0.5447 - val_accuracy: 0.5625 - val_loss: 0.8327\n",
      "Epoch 76/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7500 - loss: 0.5202 - val_accuracy: 0.4375 - val_loss: 0.7125\n",
      "Epoch 77/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7969 - loss: 0.4776 - val_accuracy: 0.6250 - val_loss: 0.6652\n",
      "Epoch 78/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7031 - loss: 0.5056 - val_accuracy: 0.5625 - val_loss: 0.9505\n",
      "Epoch 79/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7500 - loss: 0.5417 - val_accuracy: 0.5625 - val_loss: 0.7002\n",
      "Epoch 80/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7500 - loss: 0.4784 - val_accuracy: 0.5000 - val_loss: 0.7219\n",
      "Epoch 81/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7656 - loss: 0.4661 - val_accuracy: 0.5625 - val_loss: 0.9516\n",
      "Epoch 82/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7344 - loss: 0.5148 - val_accuracy: 0.6250 - val_loss: 0.7296\n",
      "Epoch 83/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7188 - loss: 0.4790 - val_accuracy: 0.5000 - val_loss: 0.7786\n",
      "Epoch 84/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7656 - loss: 0.4486 - val_accuracy: 0.5625 - val_loss: 0.9320\n",
      "Epoch 85/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.4831 - val_accuracy: 0.6250 - val_loss: 0.7668\n",
      "Epoch 86/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7344 - loss: 0.4705 - val_accuracy: 0.5000 - val_loss: 0.8310\n",
      "Epoch 87/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7969 - loss: 0.4406 - val_accuracy: 0.4375 - val_loss: 0.9256\n",
      "Epoch 88/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.4590 - val_accuracy: 0.6250 - val_loss: 0.8104\n",
      "Epoch 89/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7969 - loss: 0.4594 - val_accuracy: 0.4375 - val_loss: 0.8883\n",
      "Epoch 90/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.4351 - val_accuracy: 0.4375 - val_loss: 0.9346\n",
      "Epoch 91/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.4400 - val_accuracy: 0.5625 - val_loss: 0.8605\n",
      "Epoch 92/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.4483 - val_accuracy: 0.4375 - val_loss: 0.9571\n",
      "Epoch 93/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.4322 - val_accuracy: 0.4375 - val_loss: 0.9512\n",
      "Epoch 94/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.4247 - val_accuracy: 0.5000 - val_loss: 0.9134\n",
      "Epoch 95/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.4357 - val_accuracy: 0.5000 - val_loss: 1.0315\n",
      "Epoch 96/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.4336 - val_accuracy: 0.5000 - val_loss: 0.9658\n",
      "Epoch 97/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.4172 - val_accuracy: 0.5000 - val_loss: 0.9682\n",
      "Epoch 98/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.4184 - val_accuracy: 0.5000 - val_loss: 1.0740\n",
      "Epoch 99/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.4275 - val_accuracy: 0.5000 - val_loss: 0.9828\n",
      "Epoch 100/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.4194 - val_accuracy: 0.4375 - val_loss: 1.0404\n",
      "Epoch 101/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.4072 - val_accuracy: 0.4375 - val_loss: 1.0557\n",
      "Epoch 102/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.4058 - val_accuracy: 0.5000 - val_loss: 1.0098\n",
      "Epoch 103/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.4114 - val_accuracy: 0.5000 - val_loss: 1.1139\n",
      "Epoch 104/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.4132 - val_accuracy: 0.5000 - val_loss: 1.0262\n",
      "Epoch 105/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.4038 - val_accuracy: 0.4375 - val_loss: 1.0757\n",
      "Epoch 106/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.3943 - val_accuracy: 0.4375 - val_loss: 1.0801\n",
      "Epoch 107/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3914 - val_accuracy: 0.5625 - val_loss: 1.0486\n",
      "Epoch 108/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7969 - loss: 0.3942 - val_accuracy: 0.5000 - val_loss: 1.1431\n",
      "Epoch 109/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3991 - val_accuracy: 0.5625 - val_loss: 1.0518\n",
      "Epoch 110/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.4005 - val_accuracy: 0.5000 - val_loss: 1.1701\n",
      "Epoch 111/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3998 - val_accuracy: 0.5625 - val_loss: 1.0652\n",
      "Epoch 112/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7969 - loss: 0.3917 - val_accuracy: 0.5000 - val_loss: 1.1457\n",
      "Epoch 113/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3827 - val_accuracy: 0.5625 - val_loss: 1.0939\n",
      "Epoch 114/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.3747 - val_accuracy: 0.5000 - val_loss: 1.1177\n",
      "Epoch 115/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.3701 - val_accuracy: 0.4375 - val_loss: 1.1398\n",
      "Epoch 116/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.3686 - val_accuracy: 0.5625 - val_loss: 1.1112\n",
      "Epoch 117/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.3701 - val_accuracy: 0.5000 - val_loss: 1.2117\n",
      "Epoch 118/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.3786 - val_accuracy: 0.6250 - val_loss: 1.1118\n",
      "Epoch 119/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7656 - loss: 0.4019 - val_accuracy: 0.5625 - val_loss: 1.3773\n",
      "Epoch 120/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7969 - loss: 0.4586 - val_accuracy: 0.6875 - val_loss: 1.1178\n",
      "Epoch 121/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7344 - loss: 0.4557 - val_accuracy: 0.5000 - val_loss: 1.2411\n",
      "Epoch 122/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3899 - val_accuracy: 0.5625 - val_loss: 1.1397\n",
      "Epoch 123/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3549 - val_accuracy: 0.6875 - val_loss: 1.0683\n",
      "Epoch 124/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7656 - loss: 0.4054 - val_accuracy: 0.5000 - val_loss: 1.2027\n",
      "Epoch 125/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.3897 - val_accuracy: 0.5000 - val_loss: 1.0920\n",
      "Epoch 126/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3495 - val_accuracy: 0.6875 - val_loss: 1.0349\n",
      "Epoch 127/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7656 - loss: 0.3919 - val_accuracy: 0.5000 - val_loss: 1.1271\n",
      "Epoch 128/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.3644 - val_accuracy: 0.5625 - val_loss: 1.0955\n",
      "Epoch 129/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.3529 - val_accuracy: 0.6250 - val_loss: 1.0171\n",
      "Epoch 130/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.3771 - val_accuracy: 0.5625 - val_loss: 1.0623\n",
      "Epoch 131/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3421 - val_accuracy: 0.5000 - val_loss: 1.1147\n",
      "Epoch 132/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.3584 - val_accuracy: 0.5625 - val_loss: 1.0191\n",
      "Epoch 133/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.3509 - val_accuracy: 0.5625 - val_loss: 1.0341\n",
      "Epoch 134/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.3372 - val_accuracy: 0.5000 - val_loss: 1.1216\n",
      "Epoch 135/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.3523 - val_accuracy: 0.5625 - val_loss: 1.0444\n",
      "Epoch 136/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.3324 - val_accuracy: 0.5625 - val_loss: 1.0383\n",
      "Epoch 137/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.3380 - val_accuracy: 0.5625 - val_loss: 1.1237\n",
      "Epoch 138/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.3395 - val_accuracy: 0.6250 - val_loss: 1.0758\n",
      "Epoch 139/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.3236 - val_accuracy: 0.5625 - val_loss: 1.0562\n",
      "Epoch 140/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.3333 - val_accuracy: 0.5625 - val_loss: 1.1370\n",
      "Epoch 141/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.3294 - val_accuracy: 0.6250 - val_loss: 1.0973\n",
      "Epoch 142/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.3161 - val_accuracy: 0.5625 - val_loss: 1.0794\n",
      "Epoch 143/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.3237 - val_accuracy: 0.5625 - val_loss: 1.1665\n",
      "Epoch 144/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.3245 - val_accuracy: 0.6250 - val_loss: 1.1056\n",
      "Epoch 145/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.3104 - val_accuracy: 0.6250 - val_loss: 1.1111\n",
      "Epoch 146/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.3086 - val_accuracy: 0.6250 - val_loss: 1.1883\n",
      "Epoch 147/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.3163 - val_accuracy: 0.5625 - val_loss: 1.1150\n",
      "Epoch 148/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.3146 - val_accuracy: 0.6250 - val_loss: 1.1870\n",
      "Epoch 149/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.3057 - val_accuracy: 0.6250 - val_loss: 1.1429\n",
      "Epoch 150/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.2967 - val_accuracy: 0.6250 - val_loss: 1.1527\n",
      "Epoch 151/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.2934 - val_accuracy: 0.6875 - val_loss: 1.1969\n",
      "Epoch 152/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2953 - val_accuracy: 0.6875 - val_loss: 1.1436\n",
      "Epoch 153/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.3029 - val_accuracy: 0.6250 - val_loss: 1.2961\n",
      "Epoch 154/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.3265 - val_accuracy: 0.7500 - val_loss: 1.1671\n",
      "Epoch 155/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.3722 - val_accuracy: 0.5625 - val_loss: 1.5008\n",
      "Epoch 156/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.4498 - val_accuracy: 0.7500 - val_loss: 1.1517\n",
      "Epoch 157/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7969 - loss: 0.3831 - val_accuracy: 0.6875 - val_loss: 1.1654\n",
      "Epoch 158/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2857 - val_accuracy: 0.6250 - val_loss: 1.2065\n",
      "Epoch 159/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.3098 - val_accuracy: 0.7500 - val_loss: 1.0790\n",
      "Epoch 160/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.3441 - val_accuracy: 0.6250 - val_loss: 1.1226\n",
      "Epoch 161/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2866 - val_accuracy: 0.6250 - val_loss: 1.1319\n",
      "Epoch 162/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2942 - val_accuracy: 0.7500 - val_loss: 1.0307\n",
      "Epoch 163/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.3144 - val_accuracy: 0.6875 - val_loss: 1.0596\n",
      "Epoch 164/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.2739 - val_accuracy: 0.6250 - val_loss: 1.1163\n",
      "Epoch 165/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2937 - val_accuracy: 0.8750 - val_loss: 1.0100\n",
      "Epoch 166/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.2886 - val_accuracy: 0.8125 - val_loss: 1.0233\n",
      "Epoch 167/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2689 - val_accuracy: 0.6250 - val_loss: 1.1084\n",
      "Epoch 168/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2881 - val_accuracy: 0.8750 - val_loss: 1.0130\n",
      "Epoch 169/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.2700 - val_accuracy: 0.8750 - val_loss: 1.0141\n",
      "Epoch 170/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.2678 - val_accuracy: 0.6250 - val_loss: 1.1009\n",
      "Epoch 171/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2778 - val_accuracy: 0.8125 - val_loss: 1.0247\n",
      "Epoch 172/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.2598 - val_accuracy: 0.8750 - val_loss: 1.0194\n",
      "Epoch 173/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2625 - val_accuracy: 0.6250 - val_loss: 1.1031\n",
      "Epoch 174/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2686 - val_accuracy: 0.8125 - val_loss: 1.0332\n",
      "Epoch 175/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2536 - val_accuracy: 0.8125 - val_loss: 1.0384\n",
      "Epoch 176/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2513 - val_accuracy: 0.6250 - val_loss: 1.1145\n",
      "Epoch 177/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2596 - val_accuracy: 0.8750 - val_loss: 1.0445\n",
      "Epoch 178/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.2543 - val_accuracy: 0.8125 - val_loss: 1.0947\n",
      "Epoch 179/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2428 - val_accuracy: 0.8125 - val_loss: 1.0950\n",
      "Epoch 180/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2383 - val_accuracy: 0.8750 - val_loss: 1.0771\n",
      "Epoch 181/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.2422 - val_accuracy: 0.6250 - val_loss: 1.1756\n",
      "Epoch 182/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2514 - val_accuracy: 0.8750 - val_loss: 1.0958\n",
      "Epoch 183/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.2657 - val_accuracy: 0.6250 - val_loss: 1.2896\n",
      "Epoch 184/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2980 - val_accuracy: 0.8750 - val_loss: 1.1428\n",
      "Epoch 185/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.3410 - val_accuracy: 0.6250 - val_loss: 1.4085\n",
      "Epoch 186/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3751 - val_accuracy: 0.9375 - val_loss: 1.1196\n",
      "Epoch 187/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.3074 - val_accuracy: 0.8125 - val_loss: 1.1411\n",
      "Epoch 188/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2271 - val_accuracy: 0.6875 - val_loss: 1.1784\n",
      "Epoch 189/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2467 - val_accuracy: 0.9375 - val_loss: 1.0921\n",
      "Epoch 190/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.2893 - val_accuracy: 0.6875 - val_loss: 1.1698\n",
      "Epoch 191/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2473 - val_accuracy: 0.8125 - val_loss: 1.1098\n",
      "Epoch 192/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2216 - val_accuracy: 0.9375 - val_loss: 1.0774\n",
      "Epoch 193/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.2605 - val_accuracy: 0.6875 - val_loss: 1.1715\n",
      "Epoch 194/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2456 - val_accuracy: 0.8125 - val_loss: 1.1025\n",
      "Epoch 195/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2149 - val_accuracy: 0.8750 - val_loss: 1.0869\n",
      "Epoch 196/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.2425 - val_accuracy: 0.6875 - val_loss: 1.1871\n",
      "Epoch 197/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2408 - val_accuracy: 0.8125 - val_loss: 1.1139\n",
      "Epoch 198/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2101 - val_accuracy: 0.8750 - val_loss: 1.1107\n",
      "Epoch 199/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2251 - val_accuracy: 0.6875 - val_loss: 1.2161\n",
      "Epoch 200/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2370 - val_accuracy: 0.8750 - val_loss: 1.1334\n",
      "Epoch 201/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2111 - val_accuracy: 0.8750 - val_loss: 1.1490\n",
      "Epoch 202/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2042 - val_accuracy: 0.7500 - val_loss: 1.2319\n",
      "Epoch 203/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2218 - val_accuracy: 0.9375 - val_loss: 1.1677\n",
      "Epoch 204/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.2228 - val_accuracy: 0.8125 - val_loss: 1.2323\n",
      "Epoch 205/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2053 - val_accuracy: 0.8125 - val_loss: 1.2071\n",
      "Epoch 206/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1924 - val_accuracy: 0.8750 - val_loss: 1.2115\n",
      "Epoch 207/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.1957 - val_accuracy: 0.7500 - val_loss: 1.2963\n",
      "Epoch 208/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.2093 - val_accuracy: 0.9375 - val_loss: 1.2448\n",
      "Epoch 209/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.2263 - val_accuracy: 0.6875 - val_loss: 1.3919\n",
      "Epoch 210/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2490 - val_accuracy: 0.9375 - val_loss: 1.2876\n",
      "Epoch 211/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2675 - val_accuracy: 0.6875 - val_loss: 1.4435\n",
      "Epoch 212/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2739 - val_accuracy: 0.9375 - val_loss: 1.2884\n",
      "Epoch 213/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2438 - val_accuracy: 0.7500 - val_loss: 1.3421\n",
      "Epoch 214/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1995 - val_accuracy: 0.8125 - val_loss: 1.2877\n",
      "Epoch 215/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1755 - val_accuracy: 0.8750 - val_loss: 1.2836\n",
      "Epoch 216/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1872 - val_accuracy: 0.7500 - val_loss: 1.3827\n",
      "Epoch 217/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2136 - val_accuracy: 0.9375 - val_loss: 1.3101\n",
      "Epoch 218/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2189 - val_accuracy: 0.7500 - val_loss: 1.3834\n",
      "Epoch 219/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1985 - val_accuracy: 0.8750 - val_loss: 1.3245\n",
      "Epoch 220/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1730 - val_accuracy: 0.8750 - val_loss: 1.3438\n",
      "Epoch 221/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1655 - val_accuracy: 0.8125 - val_loss: 1.3978\n",
      "Epoch 222/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1759 - val_accuracy: 0.9375 - val_loss: 1.3774\n",
      "Epoch 223/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1963 - val_accuracy: 0.7500 - val_loss: 1.5052\n",
      "Epoch 224/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2242 - val_accuracy: 0.9375 - val_loss: 1.4301\n",
      "Epoch 225/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2467 - val_accuracy: 0.7500 - val_loss: 1.5643\n",
      "Epoch 226/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.2542 - val_accuracy: 0.9375 - val_loss: 1.4322\n",
      "Epoch 227/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2234 - val_accuracy: 0.7500 - val_loss: 1.4735\n",
      "Epoch 228/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1784 - val_accuracy: 0.8750 - val_loss: 1.4225\n",
      "Epoch 229/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9531 - loss: 0.1521 - val_accuracy: 0.9375 - val_loss: 1.4257\n",
      "Epoch 230/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1597 - val_accuracy: 0.7500 - val_loss: 1.5089\n",
      "Epoch 231/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1857 - val_accuracy: 0.9375 - val_loss: 1.4615\n",
      "Epoch 232/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.1982 - val_accuracy: 0.7500 - val_loss: 1.5365\n",
      "Epoch 233/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1861 - val_accuracy: 0.9375 - val_loss: 1.4736\n",
      "Epoch 234/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1588 - val_accuracy: 0.8125 - val_loss: 1.4994\n",
      "Epoch 235/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9688 - loss: 0.1425 - val_accuracy: 0.8125 - val_loss: 1.5216\n",
      "Epoch 236/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9531 - loss: 0.1426 - val_accuracy: 0.9375 - val_loss: 1.5245\n",
      "Epoch 237/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1560 - val_accuracy: 0.7500 - val_loss: 1.6216\n",
      "Epoch 238/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1832 - val_accuracy: 0.9375 - val_loss: 1.5875\n",
      "Epoch 239/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.2206 - val_accuracy: 0.7500 - val_loss: 1.7392\n",
      "Epoch 240/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2625 - val_accuracy: 0.9375 - val_loss: 1.6167\n",
      "Epoch 241/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.2584 - val_accuracy: 0.7500 - val_loss: 1.6619\n",
      "Epoch 242/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1983 - val_accuracy: 0.9375 - val_loss: 1.5536\n",
      "Epoch 243/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1376 - val_accuracy: 0.9375 - val_loss: 1.5540\n",
      "Epoch 244/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1370 - val_accuracy: 0.7500 - val_loss: 1.6381\n",
      "Epoch 245/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1771 - val_accuracy: 0.9375 - val_loss: 1.5890\n",
      "Epoch 246/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1863 - val_accuracy: 0.8125 - val_loss: 1.6269\n",
      "Epoch 247/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1515 - val_accuracy: 0.8750 - val_loss: 1.5941\n",
      "Epoch 248/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9844 - loss: 0.1241 - val_accuracy: 0.9375 - val_loss: 1.6087\n",
      "Epoch 249/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9375 - loss: 0.1375 - val_accuracy: 0.7500 - val_loss: 1.6943\n",
      "Epoch 250/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1642 - val_accuracy: 0.9375 - val_loss: 1.6542\n",
      "Epoch 251/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1623 - val_accuracy: 0.8125 - val_loss: 1.6985\n",
      "Epoch 252/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9375 - loss: 0.1388 - val_accuracy: 0.8750 - val_loss: 1.6716\n",
      "Epoch 253/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9531 - loss: 0.1174 - val_accuracy: 0.8750 - val_loss: 1.6903\n",
      "Epoch 254/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9688 - loss: 0.1143 - val_accuracy: 0.8125 - val_loss: 1.7445\n",
      "Epoch 255/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9531 - loss: 0.1268 - val_accuracy: 0.9375 - val_loss: 1.7439\n",
      "Epoch 256/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1488 - val_accuracy: 0.7500 - val_loss: 1.8518\n",
      "Epoch 257/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.1817 - val_accuracy: 0.9375 - val_loss: 1.8076\n",
      "Epoch 258/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2137 - val_accuracy: 0.7500 - val_loss: 1.9187\n",
      "Epoch 259/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2313 - val_accuracy: 0.9375 - val_loss: 1.7919\n",
      "Epoch 260/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.1940 - val_accuracy: 0.7500 - val_loss: 1.7968\n",
      "Epoch 261/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9375 - loss: 0.1348 - val_accuracy: 0.8125 - val_loss: 1.7421\n",
      "Epoch 262/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9844 - loss: 0.1020 - val_accuracy: 0.9375 - val_loss: 1.7501\n",
      "Epoch 263/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9375 - loss: 0.1175 - val_accuracy: 0.7500 - val_loss: 1.8355\n",
      "Epoch 264/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1519 - val_accuracy: 0.9375 - val_loss: 1.8001\n",
      "Epoch 265/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1547 - val_accuracy: 0.7500 - val_loss: 1.8380\n",
      "Epoch 266/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9375 - loss: 0.1262 - val_accuracy: 0.9375 - val_loss: 1.8075\n",
      "Epoch 267/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0980 - val_accuracy: 0.9375 - val_loss: 1.8271\n",
      "Epoch 268/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0962 - val_accuracy: 0.8125 - val_loss: 1.8884\n",
      "Epoch 269/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9531 - loss: 0.1150 - val_accuracy: 0.9375 - val_loss: 1.8909\n",
      "Epoch 270/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1363 - val_accuracy: 0.7500 - val_loss: 1.9669\n",
      "Epoch 271/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1478 - val_accuracy: 0.9375 - val_loss: 1.9221\n",
      "Epoch 272/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1424 - val_accuracy: 0.7500 - val_loss: 1.9644\n",
      "Epoch 273/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9531 - loss: 0.1254 - val_accuracy: 0.9375 - val_loss: 1.9187\n",
      "Epoch 274/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9531 - loss: 0.1042 - val_accuracy: 0.8125 - val_loss: 1.9411\n",
      "Epoch 275/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9688 - loss: 0.0878 - val_accuracy: 0.8125 - val_loss: 1.9422\n",
      "Epoch 276/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0793 - val_accuracy: 0.8750 - val_loss: 1.9643\n",
      "Epoch 277/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0782 - val_accuracy: 0.8125 - val_loss: 2.0090\n",
      "Epoch 278/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9688 - loss: 0.0835 - val_accuracy: 0.9375 - val_loss: 2.0302\n",
      "Epoch 279/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9531 - loss: 0.0984 - val_accuracy: 0.7500 - val_loss: 2.1364\n",
      "Epoch 280/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1411 - val_accuracy: 0.9375 - val_loss: 2.1637\n",
      "Epoch 281/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.2568 - val_accuracy: 0.6875 - val_loss: 2.4828\n",
      "Epoch 282/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.4712 - val_accuracy: 0.9375 - val_loss: 2.2004\n",
      "Epoch 283/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.4359 - val_accuracy: 0.7500 - val_loss: 2.0352\n",
      "Epoch 284/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1255 - val_accuracy: 0.7500 - val_loss: 1.9956\n",
      "Epoch 285/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1393 - val_accuracy: 0.9375 - val_loss: 1.9613\n",
      "Epoch 286/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.2799 - val_accuracy: 0.8125 - val_loss: 1.8807\n",
      "Epoch 287/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9844 - loss: 0.1092 - val_accuracy: 0.7500 - val_loss: 1.9132\n",
      "Epoch 288/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1523 - val_accuracy: 0.9375 - val_loss: 1.8490\n",
      "Epoch 289/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.1810 - val_accuracy: 0.8750 - val_loss: 1.7915\n",
      "Epoch 290/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9844 - loss: 0.0829 - val_accuracy: 0.7500 - val_loss: 1.9069\n",
      "Epoch 291/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1635 - val_accuracy: 0.9375 - val_loss: 1.7906\n",
      "Epoch 292/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9688 - loss: 0.0933 - val_accuracy: 0.9375 - val_loss: 1.8043\n",
      "Epoch 293/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1207 - val_accuracy: 0.7500 - val_loss: 1.8600\n",
      "Epoch 294/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1179 - val_accuracy: 0.8125 - val_loss: 1.8190\n",
      "Epoch 295/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9844 - loss: 0.0877 - val_accuracy: 0.9375 - val_loss: 1.8077\n",
      "Epoch 296/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9375 - loss: 0.1253 - val_accuracy: 0.8125 - val_loss: 1.8004\n",
      "Epoch 297/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0777 - val_accuracy: 0.7500 - val_loss: 1.8660\n",
      "Epoch 298/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9375 - loss: 0.1126 - val_accuracy: 0.8750 - val_loss: 1.7928\n",
      "Epoch 299/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9844 - loss: 0.0825 - val_accuracy: 0.9375 - val_loss: 1.7956\n",
      "Epoch 300/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9688 - loss: 0.0919 - val_accuracy: 0.8125 - val_loss: 1.8401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fcc833e660>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ✅ 데이터 분할 (Train / Validation)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
    "\n",
    "# ✅ Train / Validation 데이터 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# ✅ 클래스 비율 확인\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(f\"📊 클래스별 샘플 개수: {dict(zip(unique, counts))}\")\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "# ✅ 정규화된 값 확인\n",
    "print(f\"X_train min after scaling: {np.min(X_train)}\")\n",
    "print(f\"X_train max after scaling: {np.max(X_train)}\")\n",
    "print(f\"X_train mean after scaling: {np.mean(X_train)}\")\n",
    "print(f\"X_train std after scaling: {np.std(X_train)}\")\n",
    "\n",
    "stgcn_model.fit(X_train, y_train, epochs=300, batch_size=64, verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "cb185c6a-391e-489c-aa8c-94ef81e2b9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n",
      "X_train min after scaling: 0.26297727227211\n",
      "X_train max after scaling: 0.7508771419525146\n",
      "X_train mean after scaling: 0.5511112809181213\n",
      "X_train std after scaling: 0.10116421431303024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7182714343070984\n",
      "X_train mean after scaling: 0.5127670764923096\n",
      "X_train std after scaling: 0.11710235476493835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7335959076881409\n",
      "X_train mean after scaling: 0.5278226137161255\n",
      "X_train std after scaling: 0.1190565899014473\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7390576004981995\n",
      "X_train mean after scaling: 0.515331506729126\n",
      "X_train std after scaling: 0.1266269087791443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.8149935603141785\n",
      "X_train mean after scaling: 0.49636149406433105\n",
      "X_train std after scaling: 0.13835875689983368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.8039849996566772\n",
      "X_train mean after scaling: 0.5207386016845703\n",
      "X_train std after scaling: 0.1212945282459259\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7791480422019958\n",
      "X_train mean after scaling: 0.5385044813156128\n",
      "X_train std after scaling: 0.12007267028093338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7497087121009827\n",
      "X_train mean after scaling: 0.5389449000358582\n",
      "X_train std after scaling: 0.11683373898267746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "X_train min after scaling: 0.30819350481033325\n",
      "X_train max after scaling: 0.7550484538078308\n",
      "X_train mean after scaling: 0.564961314201355\n",
      "X_train std after scaling: 0.09649699181318283\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "X_train min after scaling: 0.31823259592056274\n",
      "X_train max after scaling: 0.7545210719108582\n",
      "X_train mean after scaling: 0.5695013999938965\n",
      "X_train std after scaling: 0.09430095553398132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7440683841705322\n",
      "X_train mean after scaling: 0.537814736366272\n",
      "X_train std after scaling: 0.11372009664773941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7393308281898499\n",
      "X_train mean after scaling: 0.5243945121765137\n",
      "X_train std after scaling: 0.11523303389549255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7442246079444885\n",
      "X_train mean after scaling: 0.520508348941803\n",
      "X_train std after scaling: 0.1158740371465683\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7340907454490662\n",
      "X_train mean after scaling: 0.5268895030021667\n",
      "X_train std after scaling: 0.11446253210306168\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7251490950584412\n",
      "X_train mean after scaling: 0.5225362777709961\n",
      "X_train std after scaling: 0.11637922376394272\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7355107665061951\n",
      "X_train mean after scaling: 0.5253604054450989\n",
      "X_train std after scaling: 0.121722511947155\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-561.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-2-561.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-3-561.json: ✅ 올바른 자세 (93.17% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-4-561.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-5-561.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-6-561.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-7-561.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-562.json: ✅ 올바른 자세 (99.99% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-563.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-564.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-565.json: ✅ 올바른 자세 (85.80% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-566.json: ✅ 올바른 자세 (85.84% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-567.json: ❌ 잘못된 자세 감지 (98.19% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-568.json: ❌ 잘못된 자세 감지 (60.60% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-569.json: ❌ 잘못된 자세 감지 (83.77% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-570.json: ❌ 잘못된 자세 감지 (99.74% 확신)\n"
     ]
    }
   ],
   "source": [
    "def predict_multiple_json_skeleton(file_paths):\n",
    "    results = {}\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            # ✅ JSON 데이터 로드\n",
    "            X_data, _ = load_json_skeleton(file_path)\n",
    "\n",
    "            # # ✅ 차원 변환 (배치 차원 추가)\n",
    "            # if len(X_data.shape) == 3:  \n",
    "            #     X_data = np.expand_dims(X_data, axis=0)  # (1, frames, joints, features)\n",
    "\n",
    "           # # ✅ 데이터 정규화\n",
    "           #  Q1 = np.percentile(X_data, 25, axis=0)\n",
    "           #  Q3 = np.percentile(X_data, 75, axis=0)\n",
    "           #  IQR = Q3 - Q1\n",
    "           #  lower_bound = Q1 - 1.5 * IQR\n",
    "           #  upper_bound = Q3 + 1.5 * IQR\n",
    "           #  X_data = np.where((X_data < lower_bound) | (X_data > upper_bound), np.median(X_data, axis=0), X_data)\n",
    "\n",
    "           #  X_data = (X_data - np.min(X_data, axis=0)) / (np.max(X_data, axis=0) - np.min(X_data, axis=0) + 1e-8)\n",
    "           #  X_data = (X_data - np.mean(X_data, axis=0)) / (np.std(X_data, axis=0) + 1e-8)\n",
    "           #  X_data = np.clip(X_data, 0, 1)\n",
    "\n",
    "\n",
    "            # ✅ 모델 예측\n",
    "            prediction = stgcn_model.predict(X_data)\n",
    "\n",
    "            \n",
    "            print(f\"X_train min after scaling: {np.min(X_data)}\")\n",
    "            print(f\"X_train max after scaling: {np.max(X_data)}\")\n",
    "            print(f\"X_train mean after scaling: {np.mean(X_data)}\")\n",
    "            print(f\"X_train std after scaling: {np.std(X_data)}\")\n",
    "            \n",
    "            # ✅ 예측 결과 처리\n",
    "            predicted_class = np.argmax(prediction, axis=-1)[0]\n",
    "            confidence = prediction[0][predicted_class]\n",
    "\n",
    "            # ✅ 결과 저장\n",
    "            if predicted_class == 0:\n",
    "                results[file_path] = f\"✅ 올바른 자세 ({confidence * 100:.2f}% 확신)\"\n",
    "            else:\n",
    "                results[file_path] = f\"❌ 잘못된 자세 감지 ({confidence * 100:.2f}% 확신)\"\n",
    "\n",
    "        except Exception as e:\n",
    "            results[file_path] = f\"❌ 예측 실패 (오류: {e})\"\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# ✅ 여러 개의 JSON 파일 리스트\n",
    "file_paths = [\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-6-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-7-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-562.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-563.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-564.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-565.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-566.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-567.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-568.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-569.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-570.json\",\n",
    "]\n",
    "\n",
    "# ✅ 예측 결과 얻기\n",
    "prediction_results = predict_multiple_json_skeleton(file_paths)\n",
    "\n",
    "# ✅ 결과 출력\n",
    "for file, result in prediction_results.items():\n",
    "    print(f\"{file}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "19c8e41f-f199-44d0-8a9a-cc9e03ded562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.metrics import Precision, Recall\n",
    "# import mediapipe as mp\n",
    "\n",
    "# # ✅ 인접 행렬 정규화 함수: self-loop 추가 및 D^(-1/2) A D^(-1/2) 적용\n",
    "# def normalize_adjacency_matrix(adj):\n",
    "#     # 자기 루프 추가\n",
    "#     np.fill_diagonal(adj, 1)\n",
    "#     # Degree matrix 계산\n",
    "#     degree = np.sum(adj, axis=1)\n",
    "#     # 0 나누기 방지\n",
    "#     degree[degree == 0] = 1\n",
    "#     D_inv_sqrt = np.diag(1.0 / np.sqrt(degree))\n",
    "#     # 정규화된 인접 행렬 계산: D^(-1/2) A D^(-1/2)\n",
    "#     A_norm = D_inv_sqrt @ adj @ D_inv_sqrt\n",
    "#     return A_norm\n",
    "    \n",
    "# # ✅ 그래프 컨볼루션 레이어 정의\n",
    "# class GraphConvLayer(layers.Layer):\n",
    "#     def __init__(self, units, adjacency_matrix):\n",
    "#         super(GraphConvLayer, self).__init__()\n",
    "#         self.units = units\n",
    "#         self.adjacency_matrix = tf.Variable(adjacency_matrix, dtype=tf.float32, trainable=False)\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         # input_shape: (batch*frames, joints, features)\n",
    "#         self.kernel = self.add_weight(\n",
    "#             shape=(input_shape[-1], self.units),\n",
    "#             initializer=\"glorot_uniform\",\n",
    "#             trainable=True\n",
    "#         )\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         # inputs: (batch*frames, joints, features)\n",
    "#         x = tf.linalg.matmul(self.adjacency_matrix, inputs)\n",
    "#         x = tf.linalg.matmul(x, self.kernel)  # 가중치 적용\n",
    "#         return tf.nn.leaky_relu(x)  # 활성화 함수 적용\n",
    "\n",
    "# # ✅ ST-GCN 모델 정의\n",
    "# class STGCN(tf.keras.Model):\n",
    "#     def __init__(self, num_joints, num_features, adjacency_matrix, num_classes):\n",
    "#         super(STGCN, self).__init__()\n",
    "#         self.graph_conv1 = GraphConvLayer(64, adjacency_matrix)\n",
    "#         self.graph_conv2 = GraphConvLayer(128, adjacency_matrix)\n",
    "#         self.graph_conv3 = GraphConvLayer(256, adjacency_matrix)  # 추가된 Graph Conv\n",
    "#         self.graph_conv4 = GraphConvLayer(512, adjacency_matrix)  # 추가된 Graph Conv\n",
    "#         self.temporal_conv1 = layers.Conv1D(512, kernel_size=5, padding=\"same\")\n",
    "#         self.temporal_conv2 = layers.Conv1D(256, kernel_size=7, padding=\"same\")\n",
    "#         self.temporal_conv3 = layers.Conv1D(128, kernel_size=7, padding=\"same\")\n",
    "#         self.temporal_conv4 = layers.Conv1D(64, kernel_size=5, padding=\"same\")\n",
    "#         self.batch_norm1 = layers.BatchNormalization()\n",
    "#         self.batch_norm2 = layers.BatchNormalization()\n",
    "#         self.batch_norm3 = layers.BatchNormalization()\n",
    "#         self.batch_norm4 = layers.BatchNormalization()\n",
    "#         self.activation = layers.Activation(\"relu\")\n",
    "#         self.global_pool = layers.GlobalAveragePooling1D()\n",
    "#         self.fc = layers.Dense(num_classes, activation=\"softmax\")\n",
    "#         self.dropout = layers.Dropout(0.5) \n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         super().build(input_shape)\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         # ✅ 입력 처리: (batch, frames, views, joints, features)\n",
    "#         if len(inputs.shape) == 5:\n",
    "#             # 여러 각도(View) 데이터가 있는 경우 평균 내기\n",
    "#             inputs = tf.reduce_mean(inputs, axis=2)  # (batch, frames, joints, features)\n",
    "        \n",
    "#         batch_size = tf.shape(inputs)[0]\n",
    "#         frames = tf.shape(inputs)[1]\n",
    "#         joints = tf.shape(inputs)[2]\n",
    "#         features = tf.shape(inputs)[3]\n",
    "        \n",
    "#         x = tf.reshape(inputs, (batch_size * frames, joints, features))  # (batch * joints, frames, features)\n",
    "        \n",
    "#         # ✅ 모델 처리\n",
    "#         x = self.graph_conv1(x)\n",
    "#         x = self.batch_norm1(x)\n",
    "#         x = self.activation(x)\n",
    "        \n",
    "#         x = self.graph_conv2(x)\n",
    "#         x = self.batch_norm2(x)\n",
    "#         x = self.activation(x)\n",
    "\n",
    "#         x = self.graph_conv3(x)\n",
    "#         x = self.batch_norm3(x)\n",
    "#         x = self.activation(x)\n",
    "\n",
    "#         x = self.graph_conv4(x)\n",
    "#         x = self.batch_norm4(x)\n",
    "#         x = self.activation(x)\n",
    "\n",
    "#         # x의 shape: (batch*frames, joints, out_features)\n",
    "#         # Temporal Conv를 위해 프레임별로 모든 관절의 정보를 하나의 벡터로 결합\n",
    "#         out_features = tf.shape(x)[-1]\n",
    "#         x = tf.reshape(x, (batch_size, frames, joints * out_features))\n",
    "\n",
    "#         x = self.temporal_conv1(x)\n",
    "#         x = self.temporal_conv2(x)\n",
    "#         x = self.temporal_conv3(x)\n",
    "#         x = self.temporal_conv4(x)\n",
    "\n",
    "#         # x = self.flatten(x)\n",
    "\n",
    "#         # frames 차원을 평균 내어 최종 특징 벡터 생성\n",
    "#         x = self.global_pool(x)\n",
    "#         x = self.dropout(x)\n",
    "        \n",
    "#         return self.fc(x)\n",
    "\n",
    "# # Mediapipe에서 제공하는 POSE_CONNECTIONS을 활용\n",
    "# mp_pose = mp.solutions.pose\n",
    "# connections = list(mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "# # ✅ 현재 선택된 19개 관절 인덱스 (사용자가 선택한 관절 리스트)\n",
    "# selected_joints = [0, 2, 5, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 21, 23, 25, 26, 28, 30, 31, 32]\n",
    "\n",
    "# # ✅ 원본 33개 관절을 기반으로 한 인접 행렬 생성\n",
    "# full_adjacency_matrix = np.zeros((33, 33))  # 전체 33개 관절을 사용한 경우\n",
    "# for joint1, joint2 in connections:\n",
    "#     full_adjacency_matrix[joint1, joint2] = 1\n",
    "#     full_adjacency_matrix[joint2, joint1] = 1  # 대칭 관계\n",
    "\n",
    "# # ✅ 선택된 관절만을 포함하는 인접 행렬 생성\n",
    "# num_joints = len(selected_joints)\n",
    "# adjacency_matrix = np.zeros((num_joints, num_joints))\n",
    "\n",
    "# for i, joint1 in enumerate(selected_joints):\n",
    "#     for j, joint2 in enumerate(selected_joints):\n",
    "#         adjacency_matrix[i, j] = full_adjacency_matrix[joint1, joint2]  # 기존 인접 행렬에서 추출\n",
    "\n",
    "# # 인접 행렬 정규화 (자기 루프 추가 및 정규화)\n",
    "# adjacency_matrix_norm = normalize_adjacency_matrix(adjacency_matrix)\n",
    "# print(f\"Normalized adjacency matrix shape: {adjacency_matrix_norm.shape}\")\n",
    "\n",
    "# num_features = 2\n",
    "# num_classes = 2  # (올바른 자세 / 잘못된 자세)\n",
    "\n",
    "# # ✅ ST-GCN 모델 생성 및 컴파일\n",
    "# del stgcn_model\n",
    "# stgcn_model = STGCN(num_joints, num_features, adjacency_matrix_norm, num_classes)\n",
    "\n",
    "# lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "#     initial_learning_rate=0.0001,\n",
    "#     decay_steps=2000,\n",
    "#     alpha=0.00001\n",
    "# )\n",
    "\n",
    "# stgcn_model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), \n",
    "#     loss=\"categorical_crossentropy\",\n",
    "#     metrics=[\"accuracy\"]\n",
    "# )\n",
    "\n",
    "# # ✅ 데이터 분할 (Train / Validation)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
    "\n",
    "# # ✅ Train / Validation 데이터 분할\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# # ✅ 클래스 비율 확인\n",
    "# unique, counts = np.unique(y_train, return_counts=True)\n",
    "# print(f\"📊 클래스별 샘플 개수: {dict(zip(unique, counts))}\")\n",
    "\n",
    "# # early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "# # ✅ 정규화된 값 확인\n",
    "# print(f\"X_train min after scaling: {np.min(X_train)}\")\n",
    "# print(f\"X_train max after scaling: {np.max(X_train)}\")\n",
    "# print(f\"X_train mean after scaling: {np.mean(X_train)}\")\n",
    "# print(f\"X_train std after scaling: {np.std(X_train)}\")\n",
    "\n",
    "# stgcn_model.fit(X_train, y_train, epochs=300, batch_size=64, verbose=1, validation_data=(X_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
