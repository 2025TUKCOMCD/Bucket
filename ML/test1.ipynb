{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "463ae2ff-2580-4da6-9a54-d3b05bb44c7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# 사용할 관절(Keypoints)\n",
    "# keypoints = [\n",
    "#     \"Nose\", \"Left Eye\", \"Right Eye\", \"Left Ear\", \"Right Ear\",\n",
    "#     \"Left Shoulder\", \"Right Shoulder\", \"Left Elbow\", \"Right Elbow\",\n",
    "#     \"Left Wrist\", \"Right Wrist\", \"Left Hip\", \"Right Hip\",\n",
    "#     \"Left Knee\", \"Right Knee\", \"Left Ankle\", \"Right Ankle\",\n",
    "#     \"Neck\", \"Left Palm\", \"Right Palm\", \"Back\", \"Waist\",\n",
    "#     \"Left Foot\", \"Right Foot\"\n",
    "# ]\n",
    "0, 2, 5, 7, 8, 11, 12, 13, 14, 15, 16, 21, 22, 23, 24, 25, 26, 27, 28\n",
    "keypoints = [\n",
    "    \"Point_0\", \"Point_2\", \"Point_5\", \"Point_7\", \"Point_8\", \"Point_11\", \n",
    "    \"Point_12\", \"Point_13\", \"Point_14\", \"Point_15\", \"Point_16\", \"Point_21\", \n",
    "    \"Point_22\", \"Point_23\", \"Point_24\", \"Point_25\", \"Point_26\", \"Point_27\", \"Point_28\"\n",
    "]\n",
    "\n",
    "\n",
    "# JSON 데이터 로드 함수\n",
    "def load_json_skeleton_view1(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    num_frames = len(data[\"frames\"])\n",
    "    num_joints = len(keypoints)\n",
    "    num_features = 2  # (x, y)\n",
    "    num_views = 1     \n",
    "\n",
    "    # ✅ (1, 프레임, 뷰, 관절, 좌표) 형태로 데이터 배열 생성\n",
    "    X_data = np.zeros((1, num_frames, num_views, num_joints, num_features), dtype=np.float32)\n",
    "\n",
    "    views = [\"view1\"]\n",
    "\n",
    "    # ✅ JSON 데이터 -> 배열 변환\n",
    "    for frame_idx, frame in enumerate(data[\"frames\"]):\n",
    "        for view_idx, view in enumerate(views):\n",
    "            pts = frame.get(view, {}).get(\"pts\", {})\n",
    "            for joint_idx, joint_name in enumerate(keypoints):\n",
    "                if joint_name in pts:\n",
    "                    X_data[0, frame_idx, view_idx, joint_idx, 0] = pts[joint_name][\"x\"]\n",
    "                    X_data[0, frame_idx, view_idx, joint_idx, 1] = pts[joint_name][\"y\"]\n",
    "\n",
    "    return X_data, data.get(\"type_info\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b1c40f17-54a1-4684-a426-716833db587c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리된 데이터 Shape: (80, 32, 5, 19, 2)\n"
     ]
    }
   ],
   "source": [
    "# ✅ JSON 데이터 로드 함수 (5개 각도 전처리)\n",
    "def load_json_skeleton(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    num_frames = len(data[\"frames\"])\n",
    "    num_joints = len(keypoints)\n",
    "    num_features = 2  # (x, y)\n",
    "    num_views = 5     # view1 ~ view5\n",
    "\n",
    "    # ✅ (1, 프레임, 뷰, 관절, 좌표) 형태로 데이터 배열 생성\n",
    "    X_data = np.zeros((1, num_frames, num_views, num_joints, num_features), dtype=np.float32)\n",
    "\n",
    "    views = [\"view1\", \"view2\", \"view3\", \"view4\", \"view5\"]\n",
    "\n",
    "    # ✅ JSON 데이터 -> 배열 변환\n",
    "    for frame_idx, frame in enumerate(data[\"frames\"]):\n",
    "        for view_idx, view in enumerate(views):\n",
    "            pts = frame.get(view, {}).get(\"pts\", {})\n",
    "            for joint_idx, joint_name in enumerate(keypoints):\n",
    "                if joint_name in pts:\n",
    "                    X_data[0, frame_idx, view_idx, joint_idx, 0] = pts[joint_name][\"x\"]\n",
    "                    X_data[0, frame_idx, view_idx, joint_idx, 1] = pts[joint_name][\"y\"]\n",
    "\n",
    "    return X_data, data.get(\"type_info\", None)\n",
    "\n",
    "# ✅ 여러 개의 JSON 파일을 한 번에 로드하는 함수 (올바른/잘못된 데이터 포함)\n",
    "def load_labeled_json_skeleton(file_paths, labels):\n",
    "    X_data_list = []\n",
    "    y_data_list = []\n",
    "\n",
    "    for file_path, label in zip(file_paths, labels):\n",
    "        X, _ = load_json_skeleton(file_path)\n",
    "        X_data_list.append(X)\n",
    "        y_data_list.append(label)\n",
    "\n",
    "    # ✅ 여러 개의 파일을 하나의 NumPy 배열로 병합\n",
    "    X_train = np.concatenate(X_data_list, axis=0)  # (batch_size, frames, views, joints, features)\n",
    "    y_train = np.array(y_data_list)                # (batch_size, )\n",
    "\n",
    "    return X_train, y_train\n",
    "    \n",
    "# ✅ 올바른 자세와 잘못된 자세 데이터를 함께 로드\n",
    "file_paths = [\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-6-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-7-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-6-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-7-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body10-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body10-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body10-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body10-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body10-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body10-6-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body10-7-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body11-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body11-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body11-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body11-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body11-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body11-6-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body11-7-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body12-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body12-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body12-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body12-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body12-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body12-6-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body12-7-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body17-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body17-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body17-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body17-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body17-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-562.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-563.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-564.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-565.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-566.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-567.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-568.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-569.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-570.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-571.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-572.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-573.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-574.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-575.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-576.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-577.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-578.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-579.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-580.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-581.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-582.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-583.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-584.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-585.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-586.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-587.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-588.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-589.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-590.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-591.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body09-1-592.json\",    #31\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-562.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-563.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-564.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-565.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-566.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-567.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-568.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-569.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/1.Training/gradu/body08-1-570.json\"\n",
    "]\n",
    "\n",
    "labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1,]  # 0 = 올바른 자세, 1 = 잘못된 자세\n",
    "\n",
    "# ✅ 전처리 실행\n",
    "X_train, y_train = load_labeled_json_skeleton(file_paths, labels)\n",
    "# X_train = X_train / np.max(X_train)\n",
    "# ✅ 전처리된 데이터 형태 확인\n",
    "print(\"전처리된 데이터 Shape:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "eb3eaa30-3fdb-4a25-ae7e-7692c4e52f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# ✅ 그래프 컨볼루션 레이어 정의\n",
    "class GraphConvLayer(layers.Layer):\n",
    "    def __init__(self, units, adjacency_matrix):\n",
    "        super(GraphConvLayer, self).__init__()\n",
    "        self.units = units\n",
    "        self.adjacency_matrix = tf.convert_to_tensor(adjacency_matrix, dtype=tf.float32)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.linalg.matmul(self.adjacency_matrix, inputs)  # 그래프 구조 반영\n",
    "        x = tf.linalg.matmul(x, self.kernel)  # 가중치 적용\n",
    "        return tf.nn.leaky_relu(x)  # 활성화 함수 적용\n",
    "\n",
    "# ✅ ST-GCN 모델 정의\n",
    "class STGCN(tf.keras.Model):\n",
    "    def __init__(self, num_joints, num_features, adjacency_matrix, num_classes):\n",
    "        super(STGCN, self).__init__()\n",
    "        self.graph_conv1 = GraphConvLayer(64, adjacency_matrix)\n",
    "        self.graph_conv2 = GraphConvLayer(128, adjacency_matrix)\n",
    "        self.temporal_conv1 = layers.Conv1D(128, kernel_size=3, padding=\"same\")\n",
    "        self.temporal_conv2 = layers.Conv1D(64, kernel_size=3, padding=\"same\")\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.batch_norm1 = layers.BatchNormalization()\n",
    "        self.batch_norm2 = layers.BatchNormalization()\n",
    "        self.activation = layers.Activation(\"relu\")\n",
    "        self.fc = layers.Dense(num_classes, activation=\"softmax\")\n",
    "        self.dropout = layers.Dropout(0.5) \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # # ✅ 입력 처리: (batch, frames, views, joints, features)\n",
    "        # if len(inputs.shape) == 5:\n",
    "        #     # 여러 각도(View) 데이터가 있는 경우 평균 내기\n",
    "        #     inputs = tf.reduce_mean(inputs, axis=2)  # (batch, frames, joints, features)\n",
    "        \n",
    "        # batch_size, frames, joints, features = tf.shape(inputs)[0], tf.shape(inputs)[1], tf.shape(inputs)[2], tf.shape(inputs)[3]\n",
    "       \n",
    "        # # inputs = tf.reshape(inputs, (batch_size, frames, joints * features))\n",
    "        \n",
    "        # # ✅ 차원 재정렬: (batch, joints, frames, features)\n",
    "        # inputs = tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "        # inputs = tf.reshape(inputs, (batch_size, joints, frames * features))\n",
    "\n",
    "        # print(X_train.shape)\n",
    "\n",
    "        # ✅ 모델 처리\n",
    "        x = self.graph_conv1(inputs)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.graph_conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.temporal_conv1(x)\n",
    "        x = self.temporal_conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return self.fc(x)\n",
    "\n",
    "# ✅ 그래프 인접 행렬 (단순 단위 행렬)\n",
    "num_joints = len(keypoints)\n",
    "num_features = 2\n",
    "num_classes = 2  # (올바른 자세 / 잘못된 자세)\n",
    "adjacency_matrix = np.identity(num_joints)\n",
    "\n",
    "# ✅ ST-GCN 모델 생성 및 컴파일\n",
    "del stgcn_model\n",
    "stgcn_model = STGCN(num_joints, num_features, adjacency_matrix, num_classes)\n",
    "stgcn_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), \n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "690f2583-93e1-4576-89c1-f4a9dbe58134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 80\n",
      "(80, 19, 64)\n",
      "(80,)\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(y_train))\n",
    "\n",
    "\n",
    "# ✅ View 차원 평균 제거 및 변환을 `fit()` 실행 전에 처리\n",
    "X_train = np.mean(X_train, axis=2)  # (80, 32, 19, 2)\n",
    "X_train = np.transpose(X_train, (0, 2, 1, 3))  # (80, 19, 32, 2)\n",
    "batch_size, joints, frames, features = X_train.shape\n",
    "X_train = np.reshape(X_train, (batch_size, joints, frames * features))  # (80, 19, 64)\n",
    "\n",
    "# ✅ Tensor 변환\n",
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5725513f-47a7-48ec-bfb8-265738ac83ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5000 - loss: 0.7186\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.7149\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.7086\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5250 - loss: 0.6925\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5125 - loss: 0.6922\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6949\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6892\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6500 - loss: 0.6814\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5625 - loss: 0.6782\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6787\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.5088e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.5054e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.5020e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.4986e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.4952e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.4919e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.4885e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.4852e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.4818e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.4785e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x19998ba3ef0>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "\n",
    "stgcn_model.fit(X_train, y_train, epochs=10, batch_size=80, verbose=1)\n",
    "stgcn_model.fit(X_train, y_train, epochs=1000, batch_size=80, verbose=0)\n",
    "stgcn_model.fit(X_train, y_train, epochs=10, batch_size=80, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cb185c6a-391e-489c-aa8c-94ef81e2b9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-561.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-2-561.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-3-561.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-4-561.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-5-561.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-6-561.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-7-561.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-562.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-563.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-564.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-565.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-566.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-567.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-568.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-569.json: ✅ 올바른 자세 (100.00% 확신)\n",
      "D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-570.json: ✅ 올바른 자세 (100.00% 확신)\n"
     ]
    }
   ],
   "source": [
    "# ✅ 여러 개의 JSON 파일을 로드하고 모델 예측 수행\n",
    "def predict_multiple_json_skeleton(file_paths):\n",
    "    results = {}\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        # JSON 데이터 로드\n",
    "        X_data, _ = load_json_skeleton(file_path)  # 기존의 JSON 로딩 함수 사용\n",
    "\n",
    "        \n",
    "        # ✅ View 차원 평균 제거 및 변환을 `fit()` 실행 전에 처리\n",
    "        X_data = np.mean(X_data, axis=2)  # (80, 32, 19, 2)\n",
    "        X_data = np.transpose(X_data, (0, 2, 1, 3))  # (80, 19, 32, 2)\n",
    "        batch_size, joints, frames, features = X_data.shape\n",
    "        X_data = np.reshape(X_data, (batch_size, joints, frames * features))  # (80, 19, 64)\n",
    "        \n",
    "        # ✅ Tensor 변환\n",
    "        X_data = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "\n",
    "        # 모델 예측\n",
    "        prediction = stgcn_model.predict(X_data)\n",
    "        predicted_class = np.argmax(prediction, axis=1)[0]  # 0 = 올바른 자세, 1 = 잘못된 자세\n",
    "        confidence = prediction[0][predicted_class]  # 선택된 클래스의 확률 값\n",
    "\n",
    "        # ✅ 결과 저장\n",
    "        if predicted_class == 0:\n",
    "            results[file_path] = f\"✅ 올바른 자세 ({confidence * 100:.2f}% 확신)\"\n",
    "        else:\n",
    "            results[file_path] = f\"❌ 잘못된 자세 감지 ({confidence * 100:.2f}% 확신)\"\n",
    "\n",
    "        #     # ✅ 결과 저장\n",
    "        # if predicted_class == 0:\n",
    "        #     results[file_path] = f\"✅ 올바른 자세\"\n",
    "        # else:\n",
    "        #     results[file_path] = f\"❌ 잘못된 자세 감지\"\n",
    "\n",
    "    return results\n",
    "\n",
    "# ✅ 여러 개의 JSON 파일 리스트\n",
    "file_paths = [\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-6-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-7-561.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-562.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-563.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-564.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-565.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-566.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-567.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-568.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-569.json\",\n",
    "    \"D:/Studying/gradu/013.피트니스자세/2.Validation/검증데이터/body_v-1-570.json\"\n",
    "]\n",
    "\n",
    "# ✅ 예측 결과 얻기\n",
    "prediction_results = predict_multiple_json_skeleton(file_paths)\n",
    "\n",
    "# ✅ 결과 출력\n",
    "for file, result in prediction_results.items():\n",
    "    print(f\"{file}: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
