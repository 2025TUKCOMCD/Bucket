{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abf520d6-147d-4913-8a3a-6e6a3b642bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Processing folder for view1: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\562-1-3-27-Z56_A\n",
      "ğŸ“‚ Processing folder for view2: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\562-1-3-27-Z56_B\n",
      "ğŸ“‚ Processing folder for view3: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\562-1-3-27-Z56_C\n",
      "ğŸ“‚ Processing folder for view4: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\562-1-3-27-Z56_D\n",
      "ğŸ“‚ Processing folder for view5: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\562-1-3-27-Z56_E\n",
      "âœ… 5ê°œ View JSON íŒŒì¼ì´ D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-562.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“‚ Processing folder for view1: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\563-1-3-27-Z56_A\n",
      "ğŸ“‚ Processing folder for view2: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\563-1-3-27-Z56_B\n",
      "ğŸ“‚ Processing folder for view3: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\563-1-3-27-Z56_C\n",
      "ğŸ“‚ Processing folder for view4: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\563-1-3-27-Z56_D\n",
      "ğŸ“‚ Processing folder for view5: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\563-1-3-27-Z56_E\n",
      "âœ… 5ê°œ View JSON íŒŒì¼ì´ D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-563.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“‚ Processing folder for view1: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\564-1-3-27-Z56_A\n",
      "ğŸ“‚ Processing folder for view2: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\564-1-3-27-Z56_B\n",
      "ğŸ“‚ Processing folder for view3: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\564-1-3-27-Z56_C\n",
      "ğŸ“‚ Processing folder for view4: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\564-1-3-27-Z56_D\n",
      "ğŸ“‚ Processing folder for view5: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\564-1-3-27-Z56_E\n",
      "âœ… 5ê°œ View JSON íŒŒì¼ì´ D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-564.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“‚ Processing folder for view1: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\565-1-3-27-Z56_A\n",
      "ğŸ“‚ Processing folder for view2: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\565-1-3-27-Z56_B\n",
      "ğŸ“‚ Processing folder for view3: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\565-1-3-27-Z56_C\n",
      "ğŸ“‚ Processing folder for view4: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\565-1-3-27-Z56_D\n",
      "ğŸ“‚ Processing folder for view5: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\565-1-3-27-Z56_E\n",
      "âœ… 5ê°œ View JSON íŒŒì¼ì´ D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-565.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“‚ Processing folder for view1: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\566-1-3-27-Z56_A\n",
      "ğŸ“‚ Processing folder for view2: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\566-1-3-27-Z56_B\n",
      "ğŸ“‚ Processing folder for view3: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\566-1-3-27-Z56_C\n",
      "ğŸ“‚ Processing folder for view4: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\566-1-3-27-Z56_D\n",
      "ğŸ“‚ Processing folder for view5: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\566-1-3-27-Z56_E\n",
      "âœ… 5ê°œ View JSON íŒŒì¼ì´ D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-566.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“‚ Processing folder for view1: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\567-1-3-27-Z56_A\n",
      "ğŸ“‚ Processing folder for view2: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\567-1-3-27-Z56_B\n",
      "ğŸ“‚ Processing folder for view3: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\567-1-3-27-Z56_C\n",
      "ğŸ“‚ Processing folder for view4: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\567-1-3-27-Z56_D\n",
      "ğŸ“‚ Processing folder for view5: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\567-1-3-27-Z56_E\n",
      "âœ… 5ê°œ View JSON íŒŒì¼ì´ D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-567.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“‚ Processing folder for view1: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\568-1-3-27-Z56_A\n",
      "ğŸ“‚ Processing folder for view2: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\568-1-3-27-Z56_B\n",
      "ğŸ“‚ Processing folder for view3: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\568-1-3-27-Z56_C\n",
      "ğŸ“‚ Processing folder for view4: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\568-1-3-27-Z56_D\n",
      "ğŸ“‚ Processing folder for view5: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\568-1-3-27-Z56_E\n",
      "âœ… 5ê°œ View JSON íŒŒì¼ì´ D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-568.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“‚ Processing folder for view1: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\569-1-3-27-Z56_A\n",
      "ğŸ“‚ Processing folder for view2: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\569-1-3-27-Z56_B\n",
      "ğŸ“‚ Processing folder for view3: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\569-1-3-27-Z56_C\n",
      "ğŸ“‚ Processing folder for view4: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\569-1-3-27-Z56_D\n",
      "ğŸ“‚ Processing folder for view5: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\569-1-3-27-Z56_E\n",
      "âœ… 5ê°œ View JSON íŒŒì¼ì´ D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-569.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“‚ Processing folder for view1: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\570-1-3-27-Z56_A\n",
      "ğŸ“‚ Processing folder for view2: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\570-1-3-27-Z56_B\n",
      "ğŸ“‚ Processing folder for view3: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\570-1-3-27-Z56_C\n",
      "ğŸ“‚ Processing folder for view4: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\570-1-3-27-Z56_D\n",
      "ğŸ“‚ Processing folder for view5: D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\\570-1-3-27-Z56_E\n",
      "âœ… 5ê°œ View JSON íŒŒì¼ì´ D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-570.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Mediapipe Pose ëª¨ë¸ ë¡œë“œ\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "selected_landmarks = [0, 2, 5, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 21, 23, 25, 26, 28, 30, 31, 32]\n",
    "\n",
    "data = {\n",
    "    \"frames\": []\n",
    "}\n",
    "\n",
    "s_idx, e_idx = 0, 5\n",
    "json_count = 562\n",
    "\n",
    "# ë¶€ëª¨ í´ë” (ì„œë¸Œ í´ë”ê°€ ì¡´ì¬í•˜ëŠ” í´ë”)\n",
    "parent_folder = \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/123\"\n",
    "json_output_path = \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-562.json\"\n",
    "\n",
    "# ì„œë¸Œ í´ë” ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ìµœëŒ€ 5ê°œ ì„ íƒ)\n",
    "while json_count < 571:\n",
    "    subfolders = sorted([f.path for f in os.scandir(parent_folder) if f.is_dir()])[s_idx:e_idx]\n",
    "    s_idx += 5\n",
    "    e_idx += 5\n",
    "    \n",
    "    # Mediapipe Pose ëª¨ë¸ ì‹¤í–‰\n",
    "    with mp_pose.Pose(static_image_mode=False, model_complexity=2, min_detection_confidence=0.5, enable_segmentation=False) as pose:\n",
    "        for folder_idx, subfolder in enumerate(subfolders):\n",
    "            view_name = f\"view{folder_idx+1}\"  # view1, view2, ..., view5\n",
    "    \n",
    "            # ì„œë¸Œ í´ë” ë‚´ ì´ë¯¸ì§€ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°\n",
    "            image_files = sorted(glob(os.path.join(subfolder, \"*.jpg\")))\n",
    "    \n",
    "            if not image_files:\n",
    "                print(f\"âš ï¸ {subfolder} ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                continue\n",
    "    \n",
    "            print(f\"ğŸ“‚ Processing folder for {view_name}: {subfolder}\")\n",
    "    \n",
    "            # í•œ ì„œë¸Œí´ë” ë‚´ 32ê°œ ì´ë¯¸ì§€ ì €ì¥\n",
    "            for img_idx, img_file in enumerate(image_files[:32]):  # 32ê°œ ì´ë¯¸ì§€ ì‚¬ìš©\n",
    "                try:\n",
    "                    # PILì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¡œë“œ\n",
    "                    image = Image.open(img_file).convert(\"RGB\")\n",
    "                    \n",
    "                    # print(f\"âœ… ì •ìƒ ë¡œë“œ: {img_file}\")\n",
    "                    image_np = np.array(image)\n",
    "    \n",
    "                    # Mediapipeì— ì…ë ¥í•  ìˆ˜ ìˆë„ë¡ ë°°ì—´ ë³€í™˜ (H, W, C ìˆœì„œ ìœ ì§€)\n",
    "                    results = pose.process(image_np)\n",
    "    \n",
    "                    # í‚¤í¬ì¸íŠ¸ ì¢Œí‘œ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ (ì •ê·œí™”ëœ ê°’ ìœ ì§€)\n",
    "                    keypoints = {}\n",
    "    \n",
    "                    if results.pose_landmarks:\n",
    "                        for idx in selected_landmarks: \n",
    "                            landmark = results.pose_landmarks.landmark[idx]\n",
    "                            keypoints[f\"Point_{idx}\"] = {\n",
    "                                \"x\": landmark.x,  # ì •ê·œí™”ëœ ê°’ (0~1)\n",
    "                                \"y\": landmark.y   # ì •ê·œí™”ëœ ê°’ (0~1)\n",
    "                            }\n",
    "    \n",
    "                    # JSON êµ¬ì¡°ì— view ì¶”ê°€\n",
    "                    frame_data = {\n",
    "                        \"pts\": keypoints,\n",
    "                        \"active\": \"Yes\" if results.pose_landmarks else \"No\",\n",
    "                        \"img_key\": img_file\n",
    "                    }\n",
    "    \n",
    "                    # í•œ í”„ë ˆì„ ë‚´ì— 5ê°œì˜ view í¬í•¨\n",
    "                    if len(data[\"frames\"]) <= img_idx:\n",
    "                        data[\"frames\"].append({})  # ì´ë¯¸ì§€ ê°œìˆ˜ë§Œí¼ í”„ë ˆì„ ìƒì„±\n",
    "    \n",
    "                    data[\"frames\"][img_idx][view_name] = frame_data\n",
    "    \n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜ ({img_file}): {e}\")\n",
    "                    continue\n",
    "    \n",
    "    with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"âœ… 5ê°œ View JSON íŒŒì¼ì´ {json_output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    json_count += 1\n",
    "    json_output_path = json_output_path.replace(str(json_count - 1), str(json_count))\n",
    "\n",
    "# s_idx, e_idx = 0, 5\n",
    "# parent_folder = \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/grad/1\"\n",
    "# json_output_path = \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-561.json\"\n",
    "\n",
    "# for i in range(7):\n",
    "#     subfolders = sorted([f.path for f in os.scandir(parent_folder) if f.is_dir()])[s_idx:e_idx]\n",
    "    \n",
    "#     # Mediapipe Pose ëª¨ë¸ ì‹¤í–‰\n",
    "#     with mp_pose.Pose(static_image_mode=False, model_complexity=2, min_detection_confidence=0.5, enable_segmentation=False) as pose:\n",
    "#         for folder_idx, subfolder in enumerate(subfolders):\n",
    "#             view_name = f\"view{folder_idx+1}\"  # view1, view2, ..., view5\n",
    "    \n",
    "#             # ì„œë¸Œ í´ë” ë‚´ ì´ë¯¸ì§€ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°\n",
    "#             image_files = sorted(glob(os.path.join(subfolder, \"*.jpg\")))\n",
    "    \n",
    "#             if not image_files:\n",
    "#                 print(f\"âš ï¸ {subfolder} ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "#                 continue\n",
    "    \n",
    "#             print(f\"ğŸ“‚ Processing folder for {view_name}: {subfolder}\")\n",
    "    \n",
    "#             # í•œ ì„œë¸Œí´ë” ë‚´ 32ê°œ ì´ë¯¸ì§€ ì €ì¥\n",
    "#             for img_idx, img_file in enumerate(image_files[:32]):  # 32ê°œ ì´ë¯¸ì§€ ì‚¬ìš©\n",
    "#                 try:\n",
    "#                     # PILì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¡œë“œ\n",
    "#                     image = Image.open(img_file).convert(\"RGB\")\n",
    "                    \n",
    "#                     # print(f\"âœ… ì •ìƒ ë¡œë“œ: {img_file}\")\n",
    "#                     image_np = np.array(image)\n",
    "    \n",
    "#                     # Mediapipeì— ì…ë ¥í•  ìˆ˜ ìˆë„ë¡ ë°°ì—´ ë³€í™˜ (H, W, C ìˆœì„œ ìœ ì§€)\n",
    "#                     results = pose.process(image_np)\n",
    "    \n",
    "#                     # í‚¤í¬ì¸íŠ¸ ì¢Œí‘œ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ (ì •ê·œí™”ëœ ê°’ ìœ ì§€)\n",
    "#                     keypoints = {}\n",
    "    \n",
    "#                     if results.pose_landmarks:\n",
    "#                         for idx in selected_landmarks:  # 19ê°œ ê´€ì ˆë§Œ ì„ íƒ\n",
    "#                             landmark = results.pose_landmarks.landmark[idx]\n",
    "#                             keypoints[f\"Point_{idx}\"] = {\n",
    "#                                 \"x\": landmark.x,  # ì •ê·œí™”ëœ ê°’ (0~1)\n",
    "#                                 \"y\": landmark.y   # ì •ê·œí™”ëœ ê°’ (0~1)\n",
    "#                             }\n",
    "    \n",
    "#                     # JSON êµ¬ì¡°ì— view ì¶”ê°€\n",
    "#                     frame_data = {\n",
    "#                         \"pts\": keypoints,\n",
    "#                         \"active\": \"Yes\" if results.pose_landmarks else \"No\",\n",
    "#                         \"img_key\": img_file\n",
    "#                     }\n",
    "    \n",
    "#                     # í•œ í”„ë ˆì„ ë‚´ì— 5ê°œì˜ view í¬í•¨\n",
    "#                     if len(data[\"frames\"]) <= img_idx:\n",
    "#                         data[\"frames\"].append({})  # ì´ë¯¸ì§€ ê°œìˆ˜ë§Œí¼ í”„ë ˆì„ ìƒì„±\n",
    "    \n",
    "#                     data[\"frames\"][img_idx][view_name] = frame_data\n",
    "    \n",
    "#                 except Exception as e:\n",
    "#                     print(f\"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜ ({img_file}): {e}\")\n",
    "#                     continue\n",
    "    \n",
    "#     with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "#     print(f\"âœ… 5ê°œ View JSON íŒŒì¼ì´ {json_output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "#     parent_folder = parent_folder.replace(f\"grad/{str(i + 1)}\", f\"grad/{str(i + 2)}\")\n",
    "#     json_output_path = json_output_path.replace(f\"body_v-{str(i + 1)}\", f\"body_v-{str(i + 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a418db5-f389-41db-811b-ff16558d48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "DEFAULT_IMAGE_WIDTH = 1280\n",
    "DEFAULT_IMAGE_HEIGHT = 960\n",
    "MIN_SHOULDER_WIDTH = 20  # ìµœì†Œ ì–´ê¹¨ ë„ˆë¹„ ì„¤ì •\n",
    "\n",
    "def compute_avg_shoulder_width(json_files):\n",
    "    widths = []\n",
    "    for json_file in json_files:\n",
    "        with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            for frame in data[\"frames\"]:\n",
    "                for view in frame:\n",
    "                    if \"pts\" in frame[view]:\n",
    "                        keypoints = frame[view][\"pts\"]\n",
    "                        left_shoulder = keypoints.get(\"Point_11\", {\"x\": None})\n",
    "                        right_shoulder = keypoints.get(\"Point_12\", {\"x\": None})\n",
    "                        if left_shoulder[\"x\"] and right_shoulder[\"x\"]:\n",
    "                            widths.append(abs(left_shoulder[\"x\"] - right_shoulder[\"x\"]))\n",
    "    return np.mean(widths) if widths else 1.0\n",
    "\n",
    "def scale_keypoints_using_shoulder(data, avg_shoulder_width, image_width=DEFAULT_IMAGE_WIDTH, image_height=DEFAULT_IMAGE_HEIGHT):\n",
    "    prev_x, prev_y = 0, 0 \n",
    "\n",
    "    for frame in data[\"frames\"]:\n",
    "        for view in frame:\n",
    "            if \"pts\" in frame[view]:  \n",
    "                keypoints = frame[view][\"pts\"]\n",
    "\n",
    "                left_shoulder = keypoints.get(\"Point_11\", {\"x\": None, \"y\": None})\n",
    "                right_shoulder = keypoints.get(\"Point_12\", {\"x\": None, \"y\": None})\n",
    "\n",
    "                if left_shoulder[\"x\"] is None or right_shoulder[\"x\"] is None:\n",
    "                    continue  \n",
    "\n",
    "                left_shoulder_x = left_shoulder[\"x\"] * image_width\n",
    "                right_shoulder_x = right_shoulder[\"x\"] * image_width\n",
    "\n",
    "                shoulder_width = abs(left_shoulder_x - right_shoulder_x) or avg_shoulder_width\n",
    "                if shoulder_width < MIN_SHOULDER_WIDTH:\n",
    "                    shoulder_width = MIN_SHOULDER_WIDTH\n",
    "\n",
    "                for point in keypoints:\n",
    "                    if keypoints[point][\"x\"] is None or keypoints[point][\"y\"] is None:\n",
    "                        continue  \n",
    "\n",
    "                    if math.isnan(keypoints[point][\"x\"]) or math.isnan(keypoints[point][\"y\"]):\n",
    "                        keypoints[point][\"x\"], keypoints[point][\"y\"] = prev_x, prev_y  \n",
    "\n",
    "                    prev_x, prev_y = keypoints[point][\"x\"], keypoints[point][\"y\"]\n",
    "\n",
    "                for point in keypoints:\n",
    "                    keypoints[point][\"x\"] = (keypoints[point][\"x\"] * image_width) / shoulder_width\n",
    "                    keypoints[point][\"y\"] = (keypoints[point][\"y\"] * image_height) / shoulder_width\n",
    "                    \n",
    "    return data\n",
    "\n",
    "input_folder = \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°\"\n",
    "output_folder = \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/scaled/\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "json_files = glob.glob(os.path.join(input_folder, \"*.json\"))\n",
    "avg_shoulder_width = compute_avg_shoulder_width(json_files)\n",
    "\n",
    "for json_file in json_files:\n",
    "    try:\n",
    "        with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            json_data = json.load(f)\n",
    "\n",
    "        scaled_data = scale_keypoints_using_shoulder(json_data, avg_shoulder_width)\n",
    "\n",
    "        file_name = os.path.basename(json_file)\n",
    "        output_json_path = os.path.join(output_folder, f\"scaled_{file_name}\")\n",
    "\n",
    "        with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(scaled_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "        print(f\"âœ… ë³€í™˜ ì™„ë£Œ: {output_json_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ íŒŒì¼ ë³€í™˜ ì˜¤ë¥˜: {json_file}, ì˜¤ë¥˜ ë‚´ìš©: {e}\")\n",
    "\n",
    "print(\"ğŸ¯ ëª¨ë“  JSON íŒŒì¼ì˜ ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388b7f2a-efb0-430f-8a80-6815ee93d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# âœ… ì´ë¯¸ì§€ í¬ê¸° (í”½ì…€ ë‹¨ìœ„)\n",
    "DEFAULT_IMAGE_WIDTH = 1920  \n",
    "DEFAULT_IMAGE_HEIGHT = 1080  \n",
    "SHOULDER_MIN_WIDTH = 30  # ìµœì†Œ ì–´ê¹¨ ë„ˆë¹„ (í”½ì…€)\n",
    "\n",
    "def scale_keypoints_using_shoulder(data, image_width=DEFAULT_IMAGE_WIDTH, image_height=DEFAULT_IMAGE_HEIGHT):\n",
    "    \"\"\"\n",
    "    Mediapipe ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ í”½ì…€ ë‹¨ìœ„ë¡œ ë³€í™˜ í›„, ì–´ê¹¨ ë„ˆë¹„ë¡œ ë‹¤ì‹œ ì •ê·œí™”í•˜ëŠ” í•¨ìˆ˜.\n",
    "    \"\"\"\n",
    "    prev_x, prev_y = 0, 0  # NaN ê°’ ë°œìƒ ì‹œ ëŒ€ì²´í•  ì´ì „ ê°’\n",
    "\n",
    "    for frame in data[\"frames\"]:\n",
    "        for view in frame:\n",
    "            if \"pts\" in frame[view]:  \n",
    "                keypoints = frame[view][\"pts\"]\n",
    "\n",
    "                # âœ… ì–´ê¹¨ ì¢Œí‘œ í™•ì¸\n",
    "                left_shoulder = keypoints.get(\"Point_11\", {\"x\": None, \"y\": None})\n",
    "                right_shoulder = keypoints.get(\"Point_12\", {\"x\": None, \"y\": None})\n",
    "\n",
    "                # ì¢Œí‘œê°€ Noneì´ê±°ë‚˜ ë¹„ì •ìƒì ì¸ ê°’ì¸ì§€ ê²€ì‚¬\n",
    "                if (left_shoulder[\"x\"] is None or right_shoulder[\"x\"] is None or\n",
    "                    left_shoulder[\"x\"] < 0 or right_shoulder[\"x\"] < 0 or\n",
    "                    left_shoulder[\"x\"] > 1 or right_shoulder[\"x\"] > 1):\n",
    "                    print(f\"âš ï¸ ì–´ê¹¨ ì¢Œí‘œê°€ ë¹„ì •ìƒì  (Point_11: {left_shoulder}, Point_12: {right_shoulder})\")\n",
    "                    continue  \n",
    "\n",
    "                # âœ… ì •ê·œí™”ëœ ê°’ì„ í”½ì…€ ë‹¨ìœ„ë¡œ ë³€í™˜\n",
    "                left_shoulder_x = left_shoulder[\"x\"] * image_width\n",
    "                right_shoulder_x = right_shoulder[\"x\"] * image_width\n",
    "\n",
    "                # âœ… ì–´ê¹¨ ë„ˆë¹„ ê³„ì‚° (í”½ì…€ ë‹¨ìœ„)\n",
    "                shoulder_width = abs(left_shoulder_x - right_shoulder_x)\n",
    "\n",
    "                # âœ… ì–´ê¹¨ ë„ˆë¹„ê°€ ë„ˆë¬´ ì‘ê±°ë‚˜ 0ì´ë©´ ë³´ì •\n",
    "                if math.isnan(shoulder_width) or shoulder_width < SHOULDER_MIN_WIDTH:\n",
    "                    print(f\"âš ï¸ ì–´ê¹¨ ë„ˆë¹„ ë¹„ì •ìƒ: {shoulder_width:.2f}px â†’ ìµœì†Œê°’({SHOULDER_MIN_WIDTH}px) ì ìš©\")\n",
    "                    shoulder_width = SHOULDER_MIN_WIDTH\n",
    "\n",
    "                # âœ… NaN ê°’ í™•ì¸ ë° ëŒ€ì²´\n",
    "                for point in keypoints:\n",
    "                    if keypoints[point][\"x\"] is None or keypoints[point][\"y\"] is None:\n",
    "                        continue  \n",
    "\n",
    "                    if math.isnan(keypoints[point][\"x\"]) or math.isnan(keypoints[point][\"y\"]):\n",
    "                        print(f\"âš ï¸ NaN ê°’ ë°œê²¬! {point} ì¢Œí‘œë¥¼ ì´ì „ í”„ë ˆì„ ê°’ìœ¼ë¡œ ëŒ€ì²´.\")\n",
    "                        keypoints[point][\"x\"] = prev_x  \n",
    "                        keypoints[point][\"y\"] = prev_y  \n",
    "\n",
    "                    prev_x, prev_y = keypoints[point][\"x\"], keypoints[point][\"y\"]\n",
    "\n",
    "                # âœ… ëª¨ë“  ì¢Œí‘œë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜ í›„ ì–´ê¹¨ ë„ˆë¹„ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”\n",
    "                for point in keypoints:\n",
    "                    keypoints[point][\"x\"] = (keypoints[point][\"x\"] * image_width) / shoulder_width\n",
    "                    keypoints[point][\"y\"] = (keypoints[point][\"y\"] * image_height) / shoulder_width\n",
    "                    \n",
    "    return data\n",
    "\n",
    "\n",
    "# âœ… JSON íŒŒì¼ì´ ìˆëŠ” í´ë” ì§€ì •\n",
    "input_folder = \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/\"  # ì›ë³¸ JSON íŒŒì¼ì´ ìˆëŠ” í´ë”\n",
    "output_folder = \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/scaled/\"  # ë³€í™˜ëœ JSON íŒŒì¼ì„ ì €ì¥í•  í´ë”\n",
    "\n",
    "# âœ… ì¶œë ¥ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# âœ… í´ë” ë‚´ ëª¨ë“  JSON íŒŒì¼ ê°€ì ¸ì˜¤ê¸°\n",
    "json_files = glob.glob(os.path.join(input_folder, \"*.json\"))\n",
    "\n",
    "# âœ… ê° JSON íŒŒì¼ì— ëŒ€í•´ ìŠ¤ì¼€ì¼ë§ ì ìš©\n",
    "for json_file in json_files:\n",
    "    try:\n",
    "        # JSON íŒŒì¼ ë¡œë“œ\n",
    "        with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            json_data = json.load(f)\n",
    "\n",
    "        scaled_data = scale_keypoints_using_shoulder(json_data, image_width=1920, image_height=1080)\n",
    "\n",
    "        # âœ… ë³€í™˜ëœ íŒŒì¼ ì €ì¥ ê²½ë¡œ ì„¤ì •\n",
    "        file_name = os.path.basename(json_file)\n",
    "        output_json_path = os.path.join(output_folder, f\"scaled_{file_name}\")\n",
    "\n",
    "        # âœ… ê²°ê³¼ ì €ì¥\n",
    "        with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(scaled_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "        print(f\"âœ… ë³€í™˜ ì™„ë£Œ: {output_json_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ íŒŒì¼ ë³€í™˜ ì˜¤ë¥˜: {json_file}, ì˜¤ë¥˜ ë‚´ìš©: {e}\")\n",
    "\n",
    "print(\"ğŸ¯ ëª¨ë“  JSON íŒŒì¼ì˜ ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
