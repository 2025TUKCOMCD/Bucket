{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "463ae2ff-2580-4da6-9a54-d3b05bb44c7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "[0, 2, 5, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 21, 23, 25, 26, 28, 30, 31, 32]\n",
    "keypoints = [\n",
    "    \"Point_0\", \"Point_2\", \"Point_5\", \"Point_7\", \"Point_8\", \"Point_11\", \n",
    "    \"Point_12\", \"Point_13\", \"Point_14\", \"Point_15\", \"Point_16\", \"Point_17\", \n",
    "    \"Point_18\", \"Point_21\", \"Point_23\", \"Point_25\", \"Point_26\", \"Point_28\", \n",
    "    \"Point_30\", \"Point_31\", \"Point_32\"\n",
    "]\n",
    "\n",
    "\n",
    "# JSON ë°ì´í„° ë¡œë“œ í•¨ìˆ˜\n",
    "def load_json_skeleton_view1(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    num_frames = len(data[\"frames\"])\n",
    "    num_joints = len(keypoints)\n",
    "    num_features = 2  # (x, y)\n",
    "    num_views = 1     \n",
    "\n",
    "    # âœ… (1, í”„ë ˆì„, ë·°, ê´€ì ˆ, ì¢Œí‘œ) í˜•íƒœë¡œ ë°ì´í„° ë°°ì—´ ìƒì„±\n",
    "    X_data = np.zeros((1, num_frames, num_views, num_joints, num_features), dtype=np.float32)\n",
    "\n",
    "    views = [\"view1\"]\n",
    "\n",
    "    # âœ… JSON ë°ì´í„° -> ë°°ì—´ ë³€í™˜\n",
    "    for frame_idx, frame in enumerate(data[\"frames\"]):\n",
    "        for view_idx, view in enumerate(views):\n",
    "            pts = frame.get(view, {}).get(\"pts\", {})\n",
    "            for joint_idx, joint_name in enumerate(keypoints):\n",
    "                if joint_name in pts:\n",
    "                    X_data[0, frame_idx, view_idx, joint_idx, 0] = pts[joint_name][\"x\"]\n",
    "                    X_data[0, frame_idx, view_idx, joint_idx, 1] = pts[joint_name][\"y\"]\n",
    "\n",
    "    return X_data, data.get(\"type_info\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b1c40f17-54a1-4684-a426-716833db587c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²˜ë¦¬ëœ ë°ì´í„° Shape: (80, 32, 5, 21, 2)\n"
     ]
    }
   ],
   "source": [
    "# âœ… JSON ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (5ê°œ ê°ë„ ì „ì²˜ë¦¬)\n",
    "def load_json_skeleton(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    num_frames = len(data[\"frames\"])\n",
    "    num_joints = len(keypoints)\n",
    "    num_features = 2  # (x, y)\n",
    "    num_views = 5     # view1 ~ view5\n",
    "\n",
    "    # âœ… (1, í”„ë ˆì„, ë·°, ê´€ì ˆ, ì¢Œí‘œ) í˜•íƒœë¡œ ë°ì´í„° ë°°ì—´ ìƒì„±\n",
    "    X_data = np.zeros((1, num_frames, num_views, num_joints, num_features), dtype=np.float32)\n",
    "\n",
    "    views = [\"view1\", \"view2\", \"view3\", \"view4\", \"view5\"]\n",
    "\n",
    "    # âœ… JSON ë°ì´í„° -> ë°°ì—´ ë³€í™˜\n",
    "    for frame_idx, frame in enumerate(data[\"frames\"]):\n",
    "        for view_idx, view in enumerate(views):\n",
    "            pts = frame.get(view, {}).get(\"pts\", {})\n",
    "            for joint_idx, joint_name in enumerate(keypoints):\n",
    "                if joint_name in pts:\n",
    "                    X_data[0, frame_idx, view_idx, joint_idx, 0] = pts[joint_name][\"x\"]\n",
    "                    X_data[0, frame_idx, view_idx, joint_idx, 1] = pts[joint_name][\"y\"]\n",
    "\n",
    "    return X_data, data.get(\"type_info\", None)\n",
    "\n",
    "# âœ… ì—¬ëŸ¬ ê°œì˜ JSON íŒŒì¼ì„ í•œ ë²ˆì— ë¡œë“œí•˜ëŠ” í•¨ìˆ˜ (ì˜¬ë°”ë¥¸/ì˜ëª»ëœ ë°ì´í„° í¬í•¨)\n",
    "def load_labeled_json_skeleton(file_paths, labels):\n",
    "    X_data_list = []\n",
    "    y_data_list = []\n",
    "\n",
    "    for file_path, label in zip(file_paths, labels):\n",
    "        X, _ = load_json_skeleton(file_path)\n",
    "        X_data_list.append(X)\n",
    "        y_data_list.append(label)\n",
    "\n",
    "    # âœ… ì—¬ëŸ¬ ê°œì˜ íŒŒì¼ì„ í•˜ë‚˜ì˜ NumPy ë°°ì—´ë¡œ ë³‘í•©\n",
    "    X_train = np.concatenate(X_data_list, axis=0)  # (batch_size, frames, views, joints, features)\n",
    "    y_train = np.array(y_data_list)                # (batch_size, )\n",
    "\n",
    "    return X_train, y_train\n",
    "    \n",
    "# âœ… ì˜¬ë°”ë¥¸ ìì„¸ì™€ ì˜ëª»ëœ ìì„¸ ë°ì´í„°ë¥¼ í•¨ê»˜ ë¡œë“œ\n",
    "file_paths = [\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body08-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body08-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body08-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body08-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body08-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body08-6-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body08-7-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-6-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-7-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body10-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body10-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body10-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body10-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body10-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body10-6-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body10-7-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body11-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body11-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body11-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body11-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body11-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body11-6-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body11-7-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body12-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body12-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body12-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body12-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body12-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body12-6-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body12-7-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body17-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body17-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body17-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body17-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body17-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-562.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-563.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-564.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-565.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-566.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-567.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-568.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-569.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-570.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-571.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-572.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-573.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-574.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-575.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-576.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-577.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-578.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-579.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-580.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-581.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-582.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-583.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-584.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-585.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-586.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-587.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-588.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-589.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-590.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-591.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body09-1-592.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body08-1-562.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body08-1-563.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body08-1-564.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body08-1-565.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body08-1-566.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body08-1-567.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body08-1-568.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body08-1-569.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/1.Training/gradu/body08-1-570.json\",\n",
    "]\n",
    "\n",
    "labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  # 0 = ì˜¬ë°”ë¥¸ ìì„¸, 1 = ì˜ëª»ëœ ìì„¸\n",
    "\n",
    "# âœ… ì „ì²˜ë¦¬ ì‹¤í–‰\n",
    "X_train, y_train = load_labeled_json_skeleton(file_paths, labels)\n",
    "# âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„° í˜•íƒœ í™•ì¸\n",
    "print(\"ì „ì²˜ë¦¬ëœ ë°ì´í„° Shape:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "eb3eaa30-3fdb-4a25-ae7e-7692c4e52f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized adjacency matrix shape: (21, 21)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import mediapipe as mp\n",
    "\n",
    "# âœ… ì¸ì ‘ í–‰ë ¬ ì •ê·œí™” í•¨ìˆ˜: self-loop ì¶”ê°€ ë° D^(-1/2) A D^(-1/2) ì ìš©\n",
    "def normalize_adjacency_matrix(adj):\n",
    "    # ìê¸° ë£¨í”„ ì¶”ê°€\n",
    "    np.fill_diagonal(adj, 1)\n",
    "    # Degree matrix ê³„ì‚°\n",
    "    degree = np.sum(adj, axis=1)\n",
    "    # 0 ë‚˜ëˆ„ê¸° ë°©ì§€\n",
    "    degree[degree == 0] = 1\n",
    "    D_inv_sqrt = np.diag(1.0 / np.sqrt(degree))\n",
    "    # ì •ê·œí™”ëœ ì¸ì ‘ í–‰ë ¬ ê³„ì‚°: D^(-1/2) A D^(-1/2)\n",
    "    A_norm = D_inv_sqrt @ adj @ D_inv_sqrt\n",
    "    return A_norm\n",
    "    \n",
    "# âœ… ê·¸ë˜í”„ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì •ì˜\n",
    "class GraphConvLayer(layers.Layer):\n",
    "    def __init__(self, units, adjacency_matrix):\n",
    "        super(GraphConvLayer, self).__init__()\n",
    "        self.units = units\n",
    "        self.adjacency_matrix = tf.Variable(adjacency_matrix, dtype=tf.float32, trainable=False)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_shape: (batch*frames, joints, features)\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs: (batch*frames, joints, features)\n",
    "        x = tf.linalg.matmul(self.adjacency_matrix, inputs)\n",
    "        x = tf.linalg.matmul(x, self.kernel)  # ê°€ì¤‘ì¹˜ ì ìš©\n",
    "        return tf.nn.leaky_relu(x)  # í™œì„±í™” í•¨ìˆ˜ ì ìš©\n",
    "\n",
    "# âœ… ST-GCN ëª¨ë¸ ì •ì˜\n",
    "class STGCN(tf.keras.Model):\n",
    "    def __init__(self, num_joints, num_features, adjacency_matrix, num_classes):\n",
    "        super(STGCN, self).__init__()\n",
    "        self.graph_conv1 = GraphConvLayer(64, adjacency_matrix)\n",
    "        self.graph_conv2 = GraphConvLayer(128, adjacency_matrix)\n",
    "        self.graph_conv3 = GraphConvLayer(256, adjacency_matrix)  # ì¶”ê°€ëœ Graph Conv\n",
    "        self.graph_conv4 = GraphConvLayer(512, adjacency_matrix)  # ì¶”ê°€ëœ Graph Conv\n",
    "        self.temporal_conv1 = layers.Conv1D(512, kernel_size=5, padding=\"same\")\n",
    "        self.temporal_conv2 = layers.Conv1D(256, kernel_size=7, padding=\"same\")\n",
    "        self.temporal_conv3 = layers.Conv1D(128, kernel_size=7, padding=\"same\")\n",
    "        self.temporal_conv4 = layers.Conv1D(64, kernel_size=5, padding=\"same\")\n",
    "        self.batch_norm1 = layers.BatchNormalization()\n",
    "        self.batch_norm2 = layers.BatchNormalization()\n",
    "        self.batch_norm3 = layers.BatchNormalization()\n",
    "        self.batch_norm4 = layers.BatchNormalization()\n",
    "        self.activation = layers.Activation(\"relu\")\n",
    "        self.global_pool = layers.GlobalAveragePooling1D()\n",
    "        self.fc = layers.Dense(num_classes, activation=\"softmax\")\n",
    "        self.dropout = layers.Dropout(0.5) \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # âœ… ì…ë ¥ ì²˜ë¦¬: (batch, frames, views, joints, features)\n",
    "        if len(inputs.shape) == 5:\n",
    "            # ì—¬ëŸ¬ ê°ë„(View) ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° í‰ê·  ë‚´ê¸°\n",
    "            inputs = tf.reduce_mean(inputs, axis=2)  # (batch, frames, joints, features)\n",
    "        \n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        frames = tf.shape(inputs)[1]\n",
    "        joints = tf.shape(inputs)[2]\n",
    "        features = tf.shape(inputs)[3]\n",
    "        \n",
    "        x = tf.reshape(inputs, (batch_size * frames, joints, features))  # (batch * joints, frames, features)\n",
    "        \n",
    "        # âœ… ëª¨ë¸ ì²˜ë¦¬\n",
    "        x = self.graph_conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.graph_conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        x = self.graph_conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        x = self.graph_conv4(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # xì˜ shape: (batch*frames, joints, out_features)\n",
    "        # Temporal Convë¥¼ ìœ„í•´ í”„ë ˆì„ë³„ë¡œ ëª¨ë“  ê´€ì ˆì˜ ì •ë³´ë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ê²°í•©\n",
    "        out_features = tf.shape(x)[-1]\n",
    "        x = tf.reshape(x, (batch_size, frames, joints * out_features))\n",
    "\n",
    "        x = self.temporal_conv1(x)\n",
    "        x = self.temporal_conv2(x)\n",
    "        x = self.temporal_conv3(x)\n",
    "        x = self.temporal_conv4(x)\n",
    "\n",
    "        # x = self.flatten(x)\n",
    "\n",
    "        # frames ì°¨ì›ì„ í‰ê·  ë‚´ì–´ ìµœì¢… íŠ¹ì§• ë²¡í„° ìƒì„±\n",
    "        x = self.global_pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return self.fc(x)\n",
    "\n",
    "# Mediapipeì—ì„œ ì œê³µí•˜ëŠ” POSE_CONNECTIONSì„ í™œìš©\n",
    "mp_pose = mp.solutions.pose\n",
    "connections = list(mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "# âœ… í˜„ì¬ ì„ íƒëœ 19ê°œ ê´€ì ˆ ì¸ë±ìŠ¤ (ì‚¬ìš©ìê°€ ì„ íƒí•œ ê´€ì ˆ ë¦¬ìŠ¤íŠ¸)\n",
    "selected_joints = [0, 2, 5, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 21, 23, 25, 26, 28, 30, 31, 32]\n",
    "\n",
    "# âœ… ì›ë³¸ 33ê°œ ê´€ì ˆì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¸ì ‘ í–‰ë ¬ ìƒì„±\n",
    "full_adjacency_matrix = np.zeros((33, 33))  # ì „ì²´ 33ê°œ ê´€ì ˆì„ ì‚¬ìš©í•œ ê²½ìš°\n",
    "for joint1, joint2 in connections:\n",
    "    full_adjacency_matrix[joint1, joint2] = 1\n",
    "    full_adjacency_matrix[joint2, joint1] = 1  # ëŒ€ì¹­ ê´€ê³„\n",
    "\n",
    "# âœ… ì„ íƒëœ ê´€ì ˆë§Œì„ í¬í•¨í•˜ëŠ” ì¸ì ‘ í–‰ë ¬ ìƒì„±\n",
    "num_joints = len(selected_joints)\n",
    "adjacency_matrix = np.zeros((num_joints, num_joints))\n",
    "\n",
    "for i, joint1 in enumerate(selected_joints):\n",
    "    for j, joint2 in enumerate(selected_joints):\n",
    "        adjacency_matrix[i, j] = full_adjacency_matrix[joint1, joint2]  # ê¸°ì¡´ ì¸ì ‘ í–‰ë ¬ì—ì„œ ì¶”ì¶œ\n",
    "\n",
    "# ì¸ì ‘ í–‰ë ¬ ì •ê·œí™” (ìê¸° ë£¨í”„ ì¶”ê°€ ë° ì •ê·œí™”)\n",
    "adjacency_matrix_norm = normalize_adjacency_matrix(adjacency_matrix)\n",
    "print(f\"Normalized adjacency matrix shape: {adjacency_matrix_norm.shape}\")\n",
    "\n",
    "num_features = 2\n",
    "num_classes = 2  # (ì˜¬ë°”ë¥¸ ìì„¸ / ì˜ëª»ëœ ìì„¸)\n",
    "\n",
    "# âœ… ST-GCN ëª¨ë¸ ìƒì„± ë° ì»´íŒŒì¼\n",
    "del stgcn_model\n",
    "stgcn_model = STGCN(num_joints, num_features, adjacency_matrix_norm, num_classes)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=0.0001,\n",
    "    decay_steps=2000,\n",
    "    alpha=0.00001\n",
    ")\n",
    "\n",
    "stgcn_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), \n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "5725513f-47a7-48ec-bfb8-265738ac83ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ê°œìˆ˜: {0.0: 64, 1.0: 64}\n",
      "X_train min after scaling: -0.07021019607782364\n",
      "X_train max after scaling: 0.8629935383796692\n",
      "X_train mean after scaling: 0.5254637002944946\n",
      "X_train std after scaling: 0.12587009370326996\n",
      "Epoch 1/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.5469 - loss: 0.6913 - val_accuracy: 0.3125 - val_loss: 2.4643\n",
      "Epoch 2/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 1.6285 - val_accuracy: 0.3125 - val_loss: 0.9842\n",
      "Epoch 3/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.7583 - val_accuracy: 0.6875 - val_loss: 0.6191\n",
      "Epoch 4/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4531 - loss: 0.8000 - val_accuracy: 0.6875 - val_loss: 0.6242\n",
      "Epoch 5/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4531 - loss: 0.8607 - val_accuracy: 0.6875 - val_loss: 0.6294\n",
      "Epoch 6/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4531 - loss: 0.7442 - val_accuracy: 0.3125 - val_loss: 0.7711\n",
      "Epoch 7/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6912 - val_accuracy: 0.3125 - val_loss: 1.0215\n",
      "Epoch 8/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5469 - loss: 0.7750 - val_accuracy: 0.3125 - val_loss: 1.0508\n",
      "Epoch 9/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.7884 - val_accuracy: 0.3125 - val_loss: 0.9190\n",
      "Epoch 10/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.7324 - val_accuracy: 0.3125 - val_loss: 0.7761\n",
      "Epoch 11/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6919 - val_accuracy: 0.6875 - val_loss: 0.6881\n",
      "Epoch 12/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4531 - loss: 0.6934 - val_accuracy: 0.6875 - val_loss: 0.6504\n",
      "Epoch 13/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4531 - loss: 0.7135 - val_accuracy: 0.6875 - val_loss: 0.6403\n",
      "Epoch 14/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4531 - loss: 0.7246 - val_accuracy: 0.6875 - val_loss: 0.6444\n",
      "Epoch 15/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4531 - loss: 0.7195 - val_accuracy: 0.6875 - val_loss: 0.6598\n",
      "Epoch 16/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4531 - loss: 0.7059 - val_accuracy: 0.6875 - val_loss: 0.6863\n",
      "Epoch 17/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4531 - loss: 0.6937 - val_accuracy: 0.3125 - val_loss: 0.7215\n",
      "Epoch 18/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6882 - val_accuracy: 0.3125 - val_loss: 0.7595\n",
      "Epoch 19/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6895 - val_accuracy: 0.3125 - val_loss: 0.7924\n",
      "Epoch 20/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6945 - val_accuracy: 0.3125 - val_loss: 0.8128\n",
      "Epoch 21/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6988 - val_accuracy: 0.3125 - val_loss: 0.8171\n",
      "Epoch 22/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6997 - val_accuracy: 0.3125 - val_loss: 0.8069\n",
      "Epoch 23/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6973 - val_accuracy: 0.3125 - val_loss: 0.7876\n",
      "Epoch 24/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6933 - val_accuracy: 0.3125 - val_loss: 0.7649\n",
      "Epoch 25/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6897 - val_accuracy: 0.3125 - val_loss: 0.7431\n",
      "Epoch 26/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6877 - val_accuracy: 0.3125 - val_loss: 0.7245\n",
      "Epoch 27/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6873 - val_accuracy: 0.3125 - val_loss: 0.7103\n",
      "Epoch 28/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6881 - val_accuracy: 0.3125 - val_loss: 0.7005\n",
      "Epoch 29/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6893 - val_accuracy: 0.3750 - val_loss: 0.6949\n",
      "Epoch 30/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5938 - loss: 0.6902 - val_accuracy: 0.4375 - val_loss: 0.6928\n",
      "Epoch 31/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6562 - loss: 0.6904 - val_accuracy: 0.3750 - val_loss: 0.6938\n",
      "Epoch 32/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6094 - loss: 0.6900 - val_accuracy: 0.3750 - val_loss: 0.6973\n",
      "Epoch 33/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6891 - val_accuracy: 0.3125 - val_loss: 0.7029\n",
      "Epoch 34/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6879 - val_accuracy: 0.3125 - val_loss: 0.7100\n",
      "Epoch 35/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6867 - val_accuracy: 0.3125 - val_loss: 0.7180\n",
      "Epoch 36/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6858 - val_accuracy: 0.3125 - val_loss: 0.7264\n",
      "Epoch 37/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6852 - val_accuracy: 0.3125 - val_loss: 0.7345\n",
      "Epoch 38/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6850 - val_accuracy: 0.3125 - val_loss: 0.7415\n",
      "Epoch 39/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6849 - val_accuracy: 0.3125 - val_loss: 0.7468\n",
      "Epoch 40/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6848 - val_accuracy: 0.3125 - val_loss: 0.7498\n",
      "Epoch 41/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6847 - val_accuracy: 0.3125 - val_loss: 0.7500\n",
      "Epoch 42/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6842 - val_accuracy: 0.3125 - val_loss: 0.7475\n",
      "Epoch 43/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6835 - val_accuracy: 0.3125 - val_loss: 0.7426\n",
      "Epoch 44/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5469 - loss: 0.6826 - val_accuracy: 0.3125 - val_loss: 0.7360\n",
      "Epoch 45/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6817 - val_accuracy: 0.3125 - val_loss: 0.7285\n",
      "Epoch 46/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6809 - val_accuracy: 0.3125 - val_loss: 0.7209\n",
      "Epoch 47/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6802 - val_accuracy: 0.3750 - val_loss: 0.7144\n",
      "Epoch 48/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6796 - val_accuracy: 0.3750 - val_loss: 0.7101\n",
      "Epoch 49/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6788 - val_accuracy: 0.3125 - val_loss: 0.7087\n",
      "Epoch 50/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6777 - val_accuracy: 0.3125 - val_loss: 0.7104\n",
      "Epoch 51/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6763 - val_accuracy: 0.3750 - val_loss: 0.7150\n",
      "Epoch 52/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6745 - val_accuracy: 0.3750 - val_loss: 0.7214\n",
      "Epoch 53/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6727 - val_accuracy: 0.3750 - val_loss: 0.7277\n",
      "Epoch 54/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6709 - val_accuracy: 0.3750 - val_loss: 0.7312\n",
      "Epoch 55/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6689 - val_accuracy: 0.3750 - val_loss: 0.7295\n",
      "Epoch 56/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6665 - val_accuracy: 0.3750 - val_loss: 0.7216\n",
      "Epoch 57/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5781 - loss: 0.6634 - val_accuracy: 0.3750 - val_loss: 0.7100\n",
      "Epoch 58/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5938 - loss: 0.6602 - val_accuracy: 0.3750 - val_loss: 0.7006\n",
      "Epoch 59/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6562 - loss: 0.6567 - val_accuracy: 0.4375 - val_loss: 0.6996\n",
      "Epoch 60/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6562 - loss: 0.6522 - val_accuracy: 0.3750 - val_loss: 0.7076\n",
      "Epoch 61/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6406 - loss: 0.6469 - val_accuracy: 0.3750 - val_loss: 0.7156\n",
      "Epoch 62/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6406 - loss: 0.6414 - val_accuracy: 0.4375 - val_loss: 0.7076\n",
      "Epoch 63/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6562 - loss: 0.6345 - val_accuracy: 0.5625 - val_loss: 0.6870\n",
      "Epoch 64/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7344 - loss: 0.6272 - val_accuracy: 0.5625 - val_loss: 0.6864\n",
      "Epoch 65/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7500 - loss: 0.6183 - val_accuracy: 0.4375 - val_loss: 0.7034\n",
      "Epoch 66/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7188 - loss: 0.6087 - val_accuracy: 0.5625 - val_loss: 0.6795\n",
      "Epoch 67/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7656 - loss: 0.5970 - val_accuracy: 0.5000 - val_loss: 0.6729\n",
      "Epoch 68/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.5843 - val_accuracy: 0.5625 - val_loss: 0.7016\n",
      "Epoch 69/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7656 - loss: 0.5716 - val_accuracy: 0.5625 - val_loss: 0.6297\n",
      "Epoch 70/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7344 - loss: 0.5648 - val_accuracy: 0.4375 - val_loss: 0.7783\n",
      "Epoch 71/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7188 - loss: 0.5644 - val_accuracy: 0.5625 - val_loss: 0.6366\n",
      "Epoch 72/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7500 - loss: 0.5373 - val_accuracy: 0.5000 - val_loss: 0.6623\n",
      "Epoch 73/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.5185 - val_accuracy: 0.5625 - val_loss: 0.7890\n",
      "Epoch 74/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7500 - loss: 0.5286 - val_accuracy: 0.6250 - val_loss: 0.6266\n",
      "Epoch 75/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6719 - loss: 0.5447 - val_accuracy: 0.5625 - val_loss: 0.8327\n",
      "Epoch 76/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7500 - loss: 0.5202 - val_accuracy: 0.4375 - val_loss: 0.7125\n",
      "Epoch 77/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7969 - loss: 0.4776 - val_accuracy: 0.6250 - val_loss: 0.6652\n",
      "Epoch 78/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7031 - loss: 0.5056 - val_accuracy: 0.5625 - val_loss: 0.9505\n",
      "Epoch 79/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7500 - loss: 0.5417 - val_accuracy: 0.5625 - val_loss: 0.7002\n",
      "Epoch 80/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7500 - loss: 0.4784 - val_accuracy: 0.5000 - val_loss: 0.7219\n",
      "Epoch 81/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7656 - loss: 0.4661 - val_accuracy: 0.5625 - val_loss: 0.9516\n",
      "Epoch 82/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7344 - loss: 0.5148 - val_accuracy: 0.6250 - val_loss: 0.7296\n",
      "Epoch 83/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7188 - loss: 0.4790 - val_accuracy: 0.5000 - val_loss: 0.7786\n",
      "Epoch 84/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7656 - loss: 0.4486 - val_accuracy: 0.5625 - val_loss: 0.9320\n",
      "Epoch 85/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.4831 - val_accuracy: 0.6250 - val_loss: 0.7668\n",
      "Epoch 86/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7344 - loss: 0.4705 - val_accuracy: 0.5000 - val_loss: 0.8310\n",
      "Epoch 87/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7969 - loss: 0.4406 - val_accuracy: 0.4375 - val_loss: 0.9256\n",
      "Epoch 88/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.4590 - val_accuracy: 0.6250 - val_loss: 0.8104\n",
      "Epoch 89/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7969 - loss: 0.4594 - val_accuracy: 0.4375 - val_loss: 0.8883\n",
      "Epoch 90/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.4351 - val_accuracy: 0.4375 - val_loss: 0.9346\n",
      "Epoch 91/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.4400 - val_accuracy: 0.5625 - val_loss: 0.8605\n",
      "Epoch 92/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.4483 - val_accuracy: 0.4375 - val_loss: 0.9571\n",
      "Epoch 93/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.4322 - val_accuracy: 0.4375 - val_loss: 0.9512\n",
      "Epoch 94/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.4247 - val_accuracy: 0.5000 - val_loss: 0.9134\n",
      "Epoch 95/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.4357 - val_accuracy: 0.5000 - val_loss: 1.0315\n",
      "Epoch 96/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.4336 - val_accuracy: 0.5000 - val_loss: 0.9658\n",
      "Epoch 97/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.4172 - val_accuracy: 0.5000 - val_loss: 0.9682\n",
      "Epoch 98/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.4184 - val_accuracy: 0.5000 - val_loss: 1.0740\n",
      "Epoch 99/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.4275 - val_accuracy: 0.5000 - val_loss: 0.9828\n",
      "Epoch 100/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.4194 - val_accuracy: 0.4375 - val_loss: 1.0404\n",
      "Epoch 101/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.4072 - val_accuracy: 0.4375 - val_loss: 1.0557\n",
      "Epoch 102/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.4058 - val_accuracy: 0.5000 - val_loss: 1.0098\n",
      "Epoch 103/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.4114 - val_accuracy: 0.5000 - val_loss: 1.1139\n",
      "Epoch 104/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.4132 - val_accuracy: 0.5000 - val_loss: 1.0262\n",
      "Epoch 105/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.4038 - val_accuracy: 0.4375 - val_loss: 1.0757\n",
      "Epoch 106/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.3943 - val_accuracy: 0.4375 - val_loss: 1.0801\n",
      "Epoch 107/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3914 - val_accuracy: 0.5625 - val_loss: 1.0486\n",
      "Epoch 108/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7969 - loss: 0.3942 - val_accuracy: 0.5000 - val_loss: 1.1431\n",
      "Epoch 109/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3991 - val_accuracy: 0.5625 - val_loss: 1.0518\n",
      "Epoch 110/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.4005 - val_accuracy: 0.5000 - val_loss: 1.1701\n",
      "Epoch 111/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3998 - val_accuracy: 0.5625 - val_loss: 1.0652\n",
      "Epoch 112/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7969 - loss: 0.3917 - val_accuracy: 0.5000 - val_loss: 1.1457\n",
      "Epoch 113/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3827 - val_accuracy: 0.5625 - val_loss: 1.0939\n",
      "Epoch 114/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.3747 - val_accuracy: 0.5000 - val_loss: 1.1177\n",
      "Epoch 115/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.3701 - val_accuracy: 0.4375 - val_loss: 1.1398\n",
      "Epoch 116/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.3686 - val_accuracy: 0.5625 - val_loss: 1.1112\n",
      "Epoch 117/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.3701 - val_accuracy: 0.5000 - val_loss: 1.2117\n",
      "Epoch 118/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.3786 - val_accuracy: 0.6250 - val_loss: 1.1118\n",
      "Epoch 119/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7656 - loss: 0.4019 - val_accuracy: 0.5625 - val_loss: 1.3773\n",
      "Epoch 120/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7969 - loss: 0.4586 - val_accuracy: 0.6875 - val_loss: 1.1178\n",
      "Epoch 121/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7344 - loss: 0.4557 - val_accuracy: 0.5000 - val_loss: 1.2411\n",
      "Epoch 122/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3899 - val_accuracy: 0.5625 - val_loss: 1.1397\n",
      "Epoch 123/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3549 - val_accuracy: 0.6875 - val_loss: 1.0683\n",
      "Epoch 124/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7656 - loss: 0.4054 - val_accuracy: 0.5000 - val_loss: 1.2027\n",
      "Epoch 125/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.3897 - val_accuracy: 0.5000 - val_loss: 1.0920\n",
      "Epoch 126/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3495 - val_accuracy: 0.6875 - val_loss: 1.0349\n",
      "Epoch 127/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7656 - loss: 0.3919 - val_accuracy: 0.5000 - val_loss: 1.1271\n",
      "Epoch 128/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.3644 - val_accuracy: 0.5625 - val_loss: 1.0955\n",
      "Epoch 129/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.3529 - val_accuracy: 0.6250 - val_loss: 1.0171\n",
      "Epoch 130/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.3771 - val_accuracy: 0.5625 - val_loss: 1.0623\n",
      "Epoch 131/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3421 - val_accuracy: 0.5000 - val_loss: 1.1147\n",
      "Epoch 132/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.3584 - val_accuracy: 0.5625 - val_loss: 1.0191\n",
      "Epoch 133/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.3509 - val_accuracy: 0.5625 - val_loss: 1.0341\n",
      "Epoch 134/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.3372 - val_accuracy: 0.5000 - val_loss: 1.1216\n",
      "Epoch 135/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.3523 - val_accuracy: 0.5625 - val_loss: 1.0444\n",
      "Epoch 136/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.3324 - val_accuracy: 0.5625 - val_loss: 1.0383\n",
      "Epoch 137/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.3380 - val_accuracy: 0.5625 - val_loss: 1.1237\n",
      "Epoch 138/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.3395 - val_accuracy: 0.6250 - val_loss: 1.0758\n",
      "Epoch 139/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.3236 - val_accuracy: 0.5625 - val_loss: 1.0562\n",
      "Epoch 140/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.3333 - val_accuracy: 0.5625 - val_loss: 1.1370\n",
      "Epoch 141/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.3294 - val_accuracy: 0.6250 - val_loss: 1.0973\n",
      "Epoch 142/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.3161 - val_accuracy: 0.5625 - val_loss: 1.0794\n",
      "Epoch 143/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.3237 - val_accuracy: 0.5625 - val_loss: 1.1665\n",
      "Epoch 144/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.3245 - val_accuracy: 0.6250 - val_loss: 1.1056\n",
      "Epoch 145/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.3104 - val_accuracy: 0.6250 - val_loss: 1.1111\n",
      "Epoch 146/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.3086 - val_accuracy: 0.6250 - val_loss: 1.1883\n",
      "Epoch 147/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.3163 - val_accuracy: 0.5625 - val_loss: 1.1150\n",
      "Epoch 148/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.3146 - val_accuracy: 0.6250 - val_loss: 1.1870\n",
      "Epoch 149/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.3057 - val_accuracy: 0.6250 - val_loss: 1.1429\n",
      "Epoch 150/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.2967 - val_accuracy: 0.6250 - val_loss: 1.1527\n",
      "Epoch 151/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.2934 - val_accuracy: 0.6875 - val_loss: 1.1969\n",
      "Epoch 152/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2953 - val_accuracy: 0.6875 - val_loss: 1.1436\n",
      "Epoch 153/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.3029 - val_accuracy: 0.6250 - val_loss: 1.2961\n",
      "Epoch 154/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.3265 - val_accuracy: 0.7500 - val_loss: 1.1671\n",
      "Epoch 155/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.3722 - val_accuracy: 0.5625 - val_loss: 1.5008\n",
      "Epoch 156/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.4498 - val_accuracy: 0.7500 - val_loss: 1.1517\n",
      "Epoch 157/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7969 - loss: 0.3831 - val_accuracy: 0.6875 - val_loss: 1.1654\n",
      "Epoch 158/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2857 - val_accuracy: 0.6250 - val_loss: 1.2065\n",
      "Epoch 159/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.3098 - val_accuracy: 0.7500 - val_loss: 1.0790\n",
      "Epoch 160/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.3441 - val_accuracy: 0.6250 - val_loss: 1.1226\n",
      "Epoch 161/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2866 - val_accuracy: 0.6250 - val_loss: 1.1319\n",
      "Epoch 162/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2942 - val_accuracy: 0.7500 - val_loss: 1.0307\n",
      "Epoch 163/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.3144 - val_accuracy: 0.6875 - val_loss: 1.0596\n",
      "Epoch 164/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.2739 - val_accuracy: 0.6250 - val_loss: 1.1163\n",
      "Epoch 165/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2937 - val_accuracy: 0.8750 - val_loss: 1.0100\n",
      "Epoch 166/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.2886 - val_accuracy: 0.8125 - val_loss: 1.0233\n",
      "Epoch 167/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2689 - val_accuracy: 0.6250 - val_loss: 1.1084\n",
      "Epoch 168/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2881 - val_accuracy: 0.8750 - val_loss: 1.0130\n",
      "Epoch 169/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.2700 - val_accuracy: 0.8750 - val_loss: 1.0141\n",
      "Epoch 170/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.2678 - val_accuracy: 0.6250 - val_loss: 1.1009\n",
      "Epoch 171/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2778 - val_accuracy: 0.8125 - val_loss: 1.0247\n",
      "Epoch 172/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.2598 - val_accuracy: 0.8750 - val_loss: 1.0194\n",
      "Epoch 173/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2625 - val_accuracy: 0.6250 - val_loss: 1.1031\n",
      "Epoch 174/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2686 - val_accuracy: 0.8125 - val_loss: 1.0332\n",
      "Epoch 175/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2536 - val_accuracy: 0.8125 - val_loss: 1.0384\n",
      "Epoch 176/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2513 - val_accuracy: 0.6250 - val_loss: 1.1145\n",
      "Epoch 177/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2596 - val_accuracy: 0.8750 - val_loss: 1.0445\n",
      "Epoch 178/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.2543 - val_accuracy: 0.8125 - val_loss: 1.0947\n",
      "Epoch 179/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2428 - val_accuracy: 0.8125 - val_loss: 1.0950\n",
      "Epoch 180/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2383 - val_accuracy: 0.8750 - val_loss: 1.0771\n",
      "Epoch 181/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.2422 - val_accuracy: 0.6250 - val_loss: 1.1756\n",
      "Epoch 182/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2514 - val_accuracy: 0.8750 - val_loss: 1.0958\n",
      "Epoch 183/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.2657 - val_accuracy: 0.6250 - val_loss: 1.2896\n",
      "Epoch 184/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2980 - val_accuracy: 0.8750 - val_loss: 1.1428\n",
      "Epoch 185/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.3410 - val_accuracy: 0.6250 - val_loss: 1.4085\n",
      "Epoch 186/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3751 - val_accuracy: 0.9375 - val_loss: 1.1196\n",
      "Epoch 187/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.3074 - val_accuracy: 0.8125 - val_loss: 1.1411\n",
      "Epoch 188/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2271 - val_accuracy: 0.6875 - val_loss: 1.1784\n",
      "Epoch 189/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2467 - val_accuracy: 0.9375 - val_loss: 1.0921\n",
      "Epoch 190/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.2893 - val_accuracy: 0.6875 - val_loss: 1.1698\n",
      "Epoch 191/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2473 - val_accuracy: 0.8125 - val_loss: 1.1098\n",
      "Epoch 192/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2216 - val_accuracy: 0.9375 - val_loss: 1.0774\n",
      "Epoch 193/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.2605 - val_accuracy: 0.6875 - val_loss: 1.1715\n",
      "Epoch 194/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2456 - val_accuracy: 0.8125 - val_loss: 1.1025\n",
      "Epoch 195/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2149 - val_accuracy: 0.8750 - val_loss: 1.0869\n",
      "Epoch 196/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.2425 - val_accuracy: 0.6875 - val_loss: 1.1871\n",
      "Epoch 197/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2408 - val_accuracy: 0.8125 - val_loss: 1.1139\n",
      "Epoch 198/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2101 - val_accuracy: 0.8750 - val_loss: 1.1107\n",
      "Epoch 199/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2251 - val_accuracy: 0.6875 - val_loss: 1.2161\n",
      "Epoch 200/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2370 - val_accuracy: 0.8750 - val_loss: 1.1334\n",
      "Epoch 201/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2111 - val_accuracy: 0.8750 - val_loss: 1.1490\n",
      "Epoch 202/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2042 - val_accuracy: 0.7500 - val_loss: 1.2319\n",
      "Epoch 203/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2218 - val_accuracy: 0.9375 - val_loss: 1.1677\n",
      "Epoch 204/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.2228 - val_accuracy: 0.8125 - val_loss: 1.2323\n",
      "Epoch 205/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2053 - val_accuracy: 0.8125 - val_loss: 1.2071\n",
      "Epoch 206/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1924 - val_accuracy: 0.8750 - val_loss: 1.2115\n",
      "Epoch 207/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.1957 - val_accuracy: 0.7500 - val_loss: 1.2963\n",
      "Epoch 208/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.2093 - val_accuracy: 0.9375 - val_loss: 1.2448\n",
      "Epoch 209/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.2263 - val_accuracy: 0.6875 - val_loss: 1.3919\n",
      "Epoch 210/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2490 - val_accuracy: 0.9375 - val_loss: 1.2876\n",
      "Epoch 211/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2675 - val_accuracy: 0.6875 - val_loss: 1.4435\n",
      "Epoch 212/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2739 - val_accuracy: 0.9375 - val_loss: 1.2884\n",
      "Epoch 213/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2438 - val_accuracy: 0.7500 - val_loss: 1.3421\n",
      "Epoch 214/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1995 - val_accuracy: 0.8125 - val_loss: 1.2877\n",
      "Epoch 215/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1755 - val_accuracy: 0.8750 - val_loss: 1.2836\n",
      "Epoch 216/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1872 - val_accuracy: 0.7500 - val_loss: 1.3827\n",
      "Epoch 217/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2136 - val_accuracy: 0.9375 - val_loss: 1.3101\n",
      "Epoch 218/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2189 - val_accuracy: 0.7500 - val_loss: 1.3834\n",
      "Epoch 219/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1985 - val_accuracy: 0.8750 - val_loss: 1.3245\n",
      "Epoch 220/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1730 - val_accuracy: 0.8750 - val_loss: 1.3438\n",
      "Epoch 221/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1655 - val_accuracy: 0.8125 - val_loss: 1.3978\n",
      "Epoch 222/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1759 - val_accuracy: 0.9375 - val_loss: 1.3774\n",
      "Epoch 223/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1963 - val_accuracy: 0.7500 - val_loss: 1.5052\n",
      "Epoch 224/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2242 - val_accuracy: 0.9375 - val_loss: 1.4301\n",
      "Epoch 225/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2467 - val_accuracy: 0.7500 - val_loss: 1.5643\n",
      "Epoch 226/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.2542 - val_accuracy: 0.9375 - val_loss: 1.4322\n",
      "Epoch 227/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2234 - val_accuracy: 0.7500 - val_loss: 1.4735\n",
      "Epoch 228/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1784 - val_accuracy: 0.8750 - val_loss: 1.4225\n",
      "Epoch 229/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9531 - loss: 0.1521 - val_accuracy: 0.9375 - val_loss: 1.4257\n",
      "Epoch 230/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1597 - val_accuracy: 0.7500 - val_loss: 1.5089\n",
      "Epoch 231/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1857 - val_accuracy: 0.9375 - val_loss: 1.4615\n",
      "Epoch 232/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.1982 - val_accuracy: 0.7500 - val_loss: 1.5365\n",
      "Epoch 233/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1861 - val_accuracy: 0.9375 - val_loss: 1.4736\n",
      "Epoch 234/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1588 - val_accuracy: 0.8125 - val_loss: 1.4994\n",
      "Epoch 235/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9688 - loss: 0.1425 - val_accuracy: 0.8125 - val_loss: 1.5216\n",
      "Epoch 236/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9531 - loss: 0.1426 - val_accuracy: 0.9375 - val_loss: 1.5245\n",
      "Epoch 237/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1560 - val_accuracy: 0.7500 - val_loss: 1.6216\n",
      "Epoch 238/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1832 - val_accuracy: 0.9375 - val_loss: 1.5875\n",
      "Epoch 239/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.2206 - val_accuracy: 0.7500 - val_loss: 1.7392\n",
      "Epoch 240/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2625 - val_accuracy: 0.9375 - val_loss: 1.6167\n",
      "Epoch 241/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.2584 - val_accuracy: 0.7500 - val_loss: 1.6619\n",
      "Epoch 242/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1983 - val_accuracy: 0.9375 - val_loss: 1.5536\n",
      "Epoch 243/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1376 - val_accuracy: 0.9375 - val_loss: 1.5540\n",
      "Epoch 244/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1370 - val_accuracy: 0.7500 - val_loss: 1.6381\n",
      "Epoch 245/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1771 - val_accuracy: 0.9375 - val_loss: 1.5890\n",
      "Epoch 246/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1863 - val_accuracy: 0.8125 - val_loss: 1.6269\n",
      "Epoch 247/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1515 - val_accuracy: 0.8750 - val_loss: 1.5941\n",
      "Epoch 248/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9844 - loss: 0.1241 - val_accuracy: 0.9375 - val_loss: 1.6087\n",
      "Epoch 249/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9375 - loss: 0.1375 - val_accuracy: 0.7500 - val_loss: 1.6943\n",
      "Epoch 250/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1642 - val_accuracy: 0.9375 - val_loss: 1.6542\n",
      "Epoch 251/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1623 - val_accuracy: 0.8125 - val_loss: 1.6985\n",
      "Epoch 252/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9375 - loss: 0.1388 - val_accuracy: 0.8750 - val_loss: 1.6716\n",
      "Epoch 253/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9531 - loss: 0.1174 - val_accuracy: 0.8750 - val_loss: 1.6903\n",
      "Epoch 254/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9688 - loss: 0.1143 - val_accuracy: 0.8125 - val_loss: 1.7445\n",
      "Epoch 255/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9531 - loss: 0.1268 - val_accuracy: 0.9375 - val_loss: 1.7439\n",
      "Epoch 256/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1488 - val_accuracy: 0.7500 - val_loss: 1.8518\n",
      "Epoch 257/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.1817 - val_accuracy: 0.9375 - val_loss: 1.8076\n",
      "Epoch 258/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.2137 - val_accuracy: 0.7500 - val_loss: 1.9187\n",
      "Epoch 259/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 0.2313 - val_accuracy: 0.9375 - val_loss: 1.7919\n",
      "Epoch 260/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.1940 - val_accuracy: 0.7500 - val_loss: 1.7968\n",
      "Epoch 261/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9375 - loss: 0.1348 - val_accuracy: 0.8125 - val_loss: 1.7421\n",
      "Epoch 262/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9844 - loss: 0.1020 - val_accuracy: 0.9375 - val_loss: 1.7501\n",
      "Epoch 263/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9375 - loss: 0.1175 - val_accuracy: 0.7500 - val_loss: 1.8355\n",
      "Epoch 264/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1519 - val_accuracy: 0.9375 - val_loss: 1.8001\n",
      "Epoch 265/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1547 - val_accuracy: 0.7500 - val_loss: 1.8380\n",
      "Epoch 266/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9375 - loss: 0.1262 - val_accuracy: 0.9375 - val_loss: 1.8075\n",
      "Epoch 267/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0980 - val_accuracy: 0.9375 - val_loss: 1.8271\n",
      "Epoch 268/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0962 - val_accuracy: 0.8125 - val_loss: 1.8884\n",
      "Epoch 269/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9531 - loss: 0.1150 - val_accuracy: 0.9375 - val_loss: 1.8909\n",
      "Epoch 270/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1363 - val_accuracy: 0.7500 - val_loss: 1.9669\n",
      "Epoch 271/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1478 - val_accuracy: 0.9375 - val_loss: 1.9221\n",
      "Epoch 272/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1424 - val_accuracy: 0.7500 - val_loss: 1.9644\n",
      "Epoch 273/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9531 - loss: 0.1254 - val_accuracy: 0.9375 - val_loss: 1.9187\n",
      "Epoch 274/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9531 - loss: 0.1042 - val_accuracy: 0.8125 - val_loss: 1.9411\n",
      "Epoch 275/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9688 - loss: 0.0878 - val_accuracy: 0.8125 - val_loss: 1.9422\n",
      "Epoch 276/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0793 - val_accuracy: 0.8750 - val_loss: 1.9643\n",
      "Epoch 277/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0782 - val_accuracy: 0.8125 - val_loss: 2.0090\n",
      "Epoch 278/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9688 - loss: 0.0835 - val_accuracy: 0.9375 - val_loss: 2.0302\n",
      "Epoch 279/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9531 - loss: 0.0984 - val_accuracy: 0.7500 - val_loss: 2.1364\n",
      "Epoch 280/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1411 - val_accuracy: 0.9375 - val_loss: 2.1637\n",
      "Epoch 281/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.2568 - val_accuracy: 0.6875 - val_loss: 2.4828\n",
      "Epoch 282/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.4712 - val_accuracy: 0.9375 - val_loss: 2.2004\n",
      "Epoch 283/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.4359 - val_accuracy: 0.7500 - val_loss: 2.0352\n",
      "Epoch 284/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1255 - val_accuracy: 0.7500 - val_loss: 1.9956\n",
      "Epoch 285/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1393 - val_accuracy: 0.9375 - val_loss: 1.9613\n",
      "Epoch 286/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8281 - loss: 0.2799 - val_accuracy: 0.8125 - val_loss: 1.8807\n",
      "Epoch 287/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9844 - loss: 0.1092 - val_accuracy: 0.7500 - val_loss: 1.9132\n",
      "Epoch 288/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1523 - val_accuracy: 0.9375 - val_loss: 1.8490\n",
      "Epoch 289/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.1810 - val_accuracy: 0.8750 - val_loss: 1.7915\n",
      "Epoch 290/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9844 - loss: 0.0829 - val_accuracy: 0.7500 - val_loss: 1.9069\n",
      "Epoch 291/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.1635 - val_accuracy: 0.9375 - val_loss: 1.7906\n",
      "Epoch 292/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9688 - loss: 0.0933 - val_accuracy: 0.9375 - val_loss: 1.8043\n",
      "Epoch 293/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1207 - val_accuracy: 0.7500 - val_loss: 1.8600\n",
      "Epoch 294/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9219 - loss: 0.1179 - val_accuracy: 0.8125 - val_loss: 1.8190\n",
      "Epoch 295/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9844 - loss: 0.0877 - val_accuracy: 0.9375 - val_loss: 1.8077\n",
      "Epoch 296/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9375 - loss: 0.1253 - val_accuracy: 0.8125 - val_loss: 1.8004\n",
      "Epoch 297/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0777 - val_accuracy: 0.7500 - val_loss: 1.8660\n",
      "Epoch 298/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9375 - loss: 0.1126 - val_accuracy: 0.8750 - val_loss: 1.7928\n",
      "Epoch 299/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9844 - loss: 0.0825 - val_accuracy: 0.9375 - val_loss: 1.7956\n",
      "Epoch 300/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9688 - loss: 0.0919 - val_accuracy: 0.8125 - val_loss: 1.8401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fcc833e660>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# âœ… ë°ì´í„° ë¶„í•  (Train / Validation)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
    "\n",
    "# âœ… Train / Validation ë°ì´í„° ë¶„í• \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# âœ… í´ë˜ìŠ¤ ë¹„ìœ¨ í™•ì¸\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(f\"ğŸ“Š í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ê°œìˆ˜: {dict(zip(unique, counts))}\")\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "# âœ… ì •ê·œí™”ëœ ê°’ í™•ì¸\n",
    "print(f\"X_train min after scaling: {np.min(X_train)}\")\n",
    "print(f\"X_train max after scaling: {np.max(X_train)}\")\n",
    "print(f\"X_train mean after scaling: {np.mean(X_train)}\")\n",
    "print(f\"X_train std after scaling: {np.std(X_train)}\")\n",
    "\n",
    "stgcn_model.fit(X_train, y_train, epochs=300, batch_size=64, verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "cb185c6a-391e-489c-aa8c-94ef81e2b9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n",
      "X_train min after scaling: 0.26297727227211\n",
      "X_train max after scaling: 0.7508771419525146\n",
      "X_train mean after scaling: 0.5511112809181213\n",
      "X_train std after scaling: 0.10116421431303024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7182714343070984\n",
      "X_train mean after scaling: 0.5127670764923096\n",
      "X_train std after scaling: 0.11710235476493835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7335959076881409\n",
      "X_train mean after scaling: 0.5278226137161255\n",
      "X_train std after scaling: 0.1190565899014473\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7390576004981995\n",
      "X_train mean after scaling: 0.515331506729126\n",
      "X_train std after scaling: 0.1266269087791443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.8149935603141785\n",
      "X_train mean after scaling: 0.49636149406433105\n",
      "X_train std after scaling: 0.13835875689983368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.8039849996566772\n",
      "X_train mean after scaling: 0.5207386016845703\n",
      "X_train std after scaling: 0.1212945282459259\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7791480422019958\n",
      "X_train mean after scaling: 0.5385044813156128\n",
      "X_train std after scaling: 0.12007267028093338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7497087121009827\n",
      "X_train mean after scaling: 0.5389449000358582\n",
      "X_train std after scaling: 0.11683373898267746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "X_train min after scaling: 0.30819350481033325\n",
      "X_train max after scaling: 0.7550484538078308\n",
      "X_train mean after scaling: 0.564961314201355\n",
      "X_train std after scaling: 0.09649699181318283\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "X_train min after scaling: 0.31823259592056274\n",
      "X_train max after scaling: 0.7545210719108582\n",
      "X_train mean after scaling: 0.5695013999938965\n",
      "X_train std after scaling: 0.09430095553398132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7440683841705322\n",
      "X_train mean after scaling: 0.537814736366272\n",
      "X_train std after scaling: 0.11372009664773941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7393308281898499\n",
      "X_train mean after scaling: 0.5243945121765137\n",
      "X_train std after scaling: 0.11523303389549255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7442246079444885\n",
      "X_train mean after scaling: 0.520508348941803\n",
      "X_train std after scaling: 0.1158740371465683\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7340907454490662\n",
      "X_train mean after scaling: 0.5268895030021667\n",
      "X_train std after scaling: 0.11446253210306168\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7251490950584412\n",
      "X_train mean after scaling: 0.5225362777709961\n",
      "X_train std after scaling: 0.11637922376394272\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "X_train min after scaling: 0.0\n",
      "X_train max after scaling: 0.7355107665061951\n",
      "X_train mean after scaling: 0.5253604054450989\n",
      "X_train std after scaling: 0.121722511947155\n",
      "D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-561.json: âœ… ì˜¬ë°”ë¥¸ ìì„¸ (100.00% í™•ì‹ )\n",
      "D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-2-561.json: âœ… ì˜¬ë°”ë¥¸ ìì„¸ (100.00% í™•ì‹ )\n",
      "D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-3-561.json: âœ… ì˜¬ë°”ë¥¸ ìì„¸ (93.17% í™•ì‹ )\n",
      "D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-4-561.json: âœ… ì˜¬ë°”ë¥¸ ìì„¸ (100.00% í™•ì‹ )\n",
      "D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-5-561.json: âœ… ì˜¬ë°”ë¥¸ ìì„¸ (100.00% í™•ì‹ )\n",
      "D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-6-561.json: âœ… ì˜¬ë°”ë¥¸ ìì„¸ (100.00% í™•ì‹ )\n",
      "D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-7-561.json: âœ… ì˜¬ë°”ë¥¸ ìì„¸ (100.00% í™•ì‹ )\n",
      "D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-562.json: âœ… ì˜¬ë°”ë¥¸ ìì„¸ (99.99% í™•ì‹ )\n",
      "D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-563.json: âœ… ì˜¬ë°”ë¥¸ ìì„¸ (100.00% í™•ì‹ )\n",
      "D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-564.json: âœ… ì˜¬ë°”ë¥¸ ìì„¸ (100.00% í™•ì‹ )\n",
      "D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-565.json: âœ… ì˜¬ë°”ë¥¸ ìì„¸ (85.80% í™•ì‹ )\n",
      "D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-566.json: âœ… ì˜¬ë°”ë¥¸ ìì„¸ (85.84% í™•ì‹ )\n",
      "D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-567.json: âŒ ì˜ëª»ëœ ìì„¸ ê°ì§€ (98.19% í™•ì‹ )\n",
      "D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-568.json: âŒ ì˜ëª»ëœ ìì„¸ ê°ì§€ (60.60% í™•ì‹ )\n",
      "D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-569.json: âŒ ì˜ëª»ëœ ìì„¸ ê°ì§€ (83.77% í™•ì‹ )\n",
      "D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-570.json: âŒ ì˜ëª»ëœ ìì„¸ ê°ì§€ (99.74% í™•ì‹ )\n"
     ]
    }
   ],
   "source": [
    "def predict_multiple_json_skeleton(file_paths):\n",
    "    results = {}\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            # âœ… JSON ë°ì´í„° ë¡œë“œ\n",
    "            X_data, _ = load_json_skeleton(file_path)\n",
    "\n",
    "            # # âœ… ì°¨ì› ë³€í™˜ (ë°°ì¹˜ ì°¨ì› ì¶”ê°€)\n",
    "            # if len(X_data.shape) == 3:  \n",
    "            #     X_data = np.expand_dims(X_data, axis=0)  # (1, frames, joints, features)\n",
    "\n",
    "           # # âœ… ë°ì´í„° ì •ê·œí™”\n",
    "           #  Q1 = np.percentile(X_data, 25, axis=0)\n",
    "           #  Q3 = np.percentile(X_data, 75, axis=0)\n",
    "           #  IQR = Q3 - Q1\n",
    "           #  lower_bound = Q1 - 1.5 * IQR\n",
    "           #  upper_bound = Q3 + 1.5 * IQR\n",
    "           #  X_data = np.where((X_data < lower_bound) | (X_data > upper_bound), np.median(X_data, axis=0), X_data)\n",
    "\n",
    "           #  X_data = (X_data - np.min(X_data, axis=0)) / (np.max(X_data, axis=0) - np.min(X_data, axis=0) + 1e-8)\n",
    "           #  X_data = (X_data - np.mean(X_data, axis=0)) / (np.std(X_data, axis=0) + 1e-8)\n",
    "           #  X_data = np.clip(X_data, 0, 1)\n",
    "\n",
    "\n",
    "            # âœ… ëª¨ë¸ ì˜ˆì¸¡\n",
    "            prediction = stgcn_model.predict(X_data)\n",
    "\n",
    "            \n",
    "            print(f\"X_train min after scaling: {np.min(X_data)}\")\n",
    "            print(f\"X_train max after scaling: {np.max(X_data)}\")\n",
    "            print(f\"X_train mean after scaling: {np.mean(X_data)}\")\n",
    "            print(f\"X_train std after scaling: {np.std(X_data)}\")\n",
    "            \n",
    "            # âœ… ì˜ˆì¸¡ ê²°ê³¼ ì²˜ë¦¬\n",
    "            predicted_class = np.argmax(prediction, axis=-1)[0]\n",
    "            confidence = prediction[0][predicted_class]\n",
    "\n",
    "            # âœ… ê²°ê³¼ ì €ì¥\n",
    "            if predicted_class == 0:\n",
    "                results[file_path] = f\"âœ… ì˜¬ë°”ë¥¸ ìì„¸ ({confidence * 100:.2f}% í™•ì‹ )\"\n",
    "            else:\n",
    "                results[file_path] = f\"âŒ ì˜ëª»ëœ ìì„¸ ê°ì§€ ({confidence * 100:.2f}% í™•ì‹ )\"\n",
    "\n",
    "        except Exception as e:\n",
    "            results[file_path] = f\"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨ (ì˜¤ë¥˜: {e})\"\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# âœ… ì—¬ëŸ¬ ê°œì˜ JSON íŒŒì¼ ë¦¬ìŠ¤íŠ¸\n",
    "file_paths = [\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-2-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-3-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-4-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-5-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-6-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-7-561.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-562.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-563.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-564.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-565.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-566.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-567.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-568.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-569.json\",\n",
    "    \"D:/Studying/gradu/013.í”¼íŠ¸ë‹ˆìŠ¤ìì„¸/2.Validation/ê²€ì¦ë°ì´í„°/body_v-1-570.json\",\n",
    "]\n",
    "\n",
    "# âœ… ì˜ˆì¸¡ ê²°ê³¼ ì–»ê¸°\n",
    "prediction_results = predict_multiple_json_skeleton(file_paths)\n",
    "\n",
    "# âœ… ê²°ê³¼ ì¶œë ¥\n",
    "for file, result in prediction_results.items():\n",
    "    print(f\"{file}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "19c8e41f-f199-44d0-8a9a-cc9e03ded562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.metrics import Precision, Recall\n",
    "# import mediapipe as mp\n",
    "\n",
    "# # âœ… ì¸ì ‘ í–‰ë ¬ ì •ê·œí™” í•¨ìˆ˜: self-loop ì¶”ê°€ ë° D^(-1/2) A D^(-1/2) ì ìš©\n",
    "# def normalize_adjacency_matrix(adj):\n",
    "#     # ìê¸° ë£¨í”„ ì¶”ê°€\n",
    "#     np.fill_diagonal(adj, 1)\n",
    "#     # Degree matrix ê³„ì‚°\n",
    "#     degree = np.sum(adj, axis=1)\n",
    "#     # 0 ë‚˜ëˆ„ê¸° ë°©ì§€\n",
    "#     degree[degree == 0] = 1\n",
    "#     D_inv_sqrt = np.diag(1.0 / np.sqrt(degree))\n",
    "#     # ì •ê·œí™”ëœ ì¸ì ‘ í–‰ë ¬ ê³„ì‚°: D^(-1/2) A D^(-1/2)\n",
    "#     A_norm = D_inv_sqrt @ adj @ D_inv_sqrt\n",
    "#     return A_norm\n",
    "    \n",
    "# # âœ… ê·¸ë˜í”„ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì •ì˜\n",
    "# class GraphConvLayer(layers.Layer):\n",
    "#     def __init__(self, units, adjacency_matrix):\n",
    "#         super(GraphConvLayer, self).__init__()\n",
    "#         self.units = units\n",
    "#         self.adjacency_matrix = tf.Variable(adjacency_matrix, dtype=tf.float32, trainable=False)\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         # input_shape: (batch*frames, joints, features)\n",
    "#         self.kernel = self.add_weight(\n",
    "#             shape=(input_shape[-1], self.units),\n",
    "#             initializer=\"glorot_uniform\",\n",
    "#             trainable=True\n",
    "#         )\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         # inputs: (batch*frames, joints, features)\n",
    "#         x = tf.linalg.matmul(self.adjacency_matrix, inputs)\n",
    "#         x = tf.linalg.matmul(x, self.kernel)  # ê°€ì¤‘ì¹˜ ì ìš©\n",
    "#         return tf.nn.leaky_relu(x)  # í™œì„±í™” í•¨ìˆ˜ ì ìš©\n",
    "\n",
    "# # âœ… ST-GCN ëª¨ë¸ ì •ì˜\n",
    "# class STGCN(tf.keras.Model):\n",
    "#     def __init__(self, num_joints, num_features, adjacency_matrix, num_classes):\n",
    "#         super(STGCN, self).__init__()\n",
    "#         self.graph_conv1 = GraphConvLayer(64, adjacency_matrix)\n",
    "#         self.graph_conv2 = GraphConvLayer(128, adjacency_matrix)\n",
    "#         self.graph_conv3 = GraphConvLayer(256, adjacency_matrix)  # ì¶”ê°€ëœ Graph Conv\n",
    "#         self.graph_conv4 = GraphConvLayer(512, adjacency_matrix)  # ì¶”ê°€ëœ Graph Conv\n",
    "#         self.temporal_conv1 = layers.Conv1D(512, kernel_size=5, padding=\"same\")\n",
    "#         self.temporal_conv2 = layers.Conv1D(256, kernel_size=7, padding=\"same\")\n",
    "#         self.temporal_conv3 = layers.Conv1D(128, kernel_size=7, padding=\"same\")\n",
    "#         self.temporal_conv4 = layers.Conv1D(64, kernel_size=5, padding=\"same\")\n",
    "#         self.batch_norm1 = layers.BatchNormalization()\n",
    "#         self.batch_norm2 = layers.BatchNormalization()\n",
    "#         self.batch_norm3 = layers.BatchNormalization()\n",
    "#         self.batch_norm4 = layers.BatchNormalization()\n",
    "#         self.activation = layers.Activation(\"relu\")\n",
    "#         self.global_pool = layers.GlobalAveragePooling1D()\n",
    "#         self.fc = layers.Dense(num_classes, activation=\"softmax\")\n",
    "#         self.dropout = layers.Dropout(0.5) \n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         super().build(input_shape)\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         # âœ… ì…ë ¥ ì²˜ë¦¬: (batch, frames, views, joints, features)\n",
    "#         if len(inputs.shape) == 5:\n",
    "#             # ì—¬ëŸ¬ ê°ë„(View) ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° í‰ê·  ë‚´ê¸°\n",
    "#             inputs = tf.reduce_mean(inputs, axis=2)  # (batch, frames, joints, features)\n",
    "        \n",
    "#         batch_size = tf.shape(inputs)[0]\n",
    "#         frames = tf.shape(inputs)[1]\n",
    "#         joints = tf.shape(inputs)[2]\n",
    "#         features = tf.shape(inputs)[3]\n",
    "        \n",
    "#         x = tf.reshape(inputs, (batch_size * frames, joints, features))  # (batch * joints, frames, features)\n",
    "        \n",
    "#         # âœ… ëª¨ë¸ ì²˜ë¦¬\n",
    "#         x = self.graph_conv1(x)\n",
    "#         x = self.batch_norm1(x)\n",
    "#         x = self.activation(x)\n",
    "        \n",
    "#         x = self.graph_conv2(x)\n",
    "#         x = self.batch_norm2(x)\n",
    "#         x = self.activation(x)\n",
    "\n",
    "#         x = self.graph_conv3(x)\n",
    "#         x = self.batch_norm3(x)\n",
    "#         x = self.activation(x)\n",
    "\n",
    "#         x = self.graph_conv4(x)\n",
    "#         x = self.batch_norm4(x)\n",
    "#         x = self.activation(x)\n",
    "\n",
    "#         # xì˜ shape: (batch*frames, joints, out_features)\n",
    "#         # Temporal Convë¥¼ ìœ„í•´ í”„ë ˆì„ë³„ë¡œ ëª¨ë“  ê´€ì ˆì˜ ì •ë³´ë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ê²°í•©\n",
    "#         out_features = tf.shape(x)[-1]\n",
    "#         x = tf.reshape(x, (batch_size, frames, joints * out_features))\n",
    "\n",
    "#         x = self.temporal_conv1(x)\n",
    "#         x = self.temporal_conv2(x)\n",
    "#         x = self.temporal_conv3(x)\n",
    "#         x = self.temporal_conv4(x)\n",
    "\n",
    "#         # x = self.flatten(x)\n",
    "\n",
    "#         # frames ì°¨ì›ì„ í‰ê·  ë‚´ì–´ ìµœì¢… íŠ¹ì§• ë²¡í„° ìƒì„±\n",
    "#         x = self.global_pool(x)\n",
    "#         x = self.dropout(x)\n",
    "        \n",
    "#         return self.fc(x)\n",
    "\n",
    "# # Mediapipeì—ì„œ ì œê³µí•˜ëŠ” POSE_CONNECTIONSì„ í™œìš©\n",
    "# mp_pose = mp.solutions.pose\n",
    "# connections = list(mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "# # âœ… í˜„ì¬ ì„ íƒëœ 19ê°œ ê´€ì ˆ ì¸ë±ìŠ¤ (ì‚¬ìš©ìê°€ ì„ íƒí•œ ê´€ì ˆ ë¦¬ìŠ¤íŠ¸)\n",
    "# selected_joints = [0, 2, 5, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 21, 23, 25, 26, 28, 30, 31, 32]\n",
    "\n",
    "# # âœ… ì›ë³¸ 33ê°œ ê´€ì ˆì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¸ì ‘ í–‰ë ¬ ìƒì„±\n",
    "# full_adjacency_matrix = np.zeros((33, 33))  # ì „ì²´ 33ê°œ ê´€ì ˆì„ ì‚¬ìš©í•œ ê²½ìš°\n",
    "# for joint1, joint2 in connections:\n",
    "#     full_adjacency_matrix[joint1, joint2] = 1\n",
    "#     full_adjacency_matrix[joint2, joint1] = 1  # ëŒ€ì¹­ ê´€ê³„\n",
    "\n",
    "# # âœ… ì„ íƒëœ ê´€ì ˆë§Œì„ í¬í•¨í•˜ëŠ” ì¸ì ‘ í–‰ë ¬ ìƒì„±\n",
    "# num_joints = len(selected_joints)\n",
    "# adjacency_matrix = np.zeros((num_joints, num_joints))\n",
    "\n",
    "# for i, joint1 in enumerate(selected_joints):\n",
    "#     for j, joint2 in enumerate(selected_joints):\n",
    "#         adjacency_matrix[i, j] = full_adjacency_matrix[joint1, joint2]  # ê¸°ì¡´ ì¸ì ‘ í–‰ë ¬ì—ì„œ ì¶”ì¶œ\n",
    "\n",
    "# # ì¸ì ‘ í–‰ë ¬ ì •ê·œí™” (ìê¸° ë£¨í”„ ì¶”ê°€ ë° ì •ê·œí™”)\n",
    "# adjacency_matrix_norm = normalize_adjacency_matrix(adjacency_matrix)\n",
    "# print(f\"Normalized adjacency matrix shape: {adjacency_matrix_norm.shape}\")\n",
    "\n",
    "# num_features = 2\n",
    "# num_classes = 2  # (ì˜¬ë°”ë¥¸ ìì„¸ / ì˜ëª»ëœ ìì„¸)\n",
    "\n",
    "# # âœ… ST-GCN ëª¨ë¸ ìƒì„± ë° ì»´íŒŒì¼\n",
    "# del stgcn_model\n",
    "# stgcn_model = STGCN(num_joints, num_features, adjacency_matrix_norm, num_classes)\n",
    "\n",
    "# lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "#     initial_learning_rate=0.0001,\n",
    "#     decay_steps=2000,\n",
    "#     alpha=0.00001\n",
    "# )\n",
    "\n",
    "# stgcn_model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), \n",
    "#     loss=\"categorical_crossentropy\",\n",
    "#     metrics=[\"accuracy\"]\n",
    "# )\n",
    "\n",
    "# # âœ… ë°ì´í„° ë¶„í•  (Train / Validation)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
    "\n",
    "# # âœ… Train / Validation ë°ì´í„° ë¶„í• \n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# # âœ… í´ë˜ìŠ¤ ë¹„ìœ¨ í™•ì¸\n",
    "# unique, counts = np.unique(y_train, return_counts=True)\n",
    "# print(f\"ğŸ“Š í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ê°œìˆ˜: {dict(zip(unique, counts))}\")\n",
    "\n",
    "# # early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "# # âœ… ì •ê·œí™”ëœ ê°’ í™•ì¸\n",
    "# print(f\"X_train min after scaling: {np.min(X_train)}\")\n",
    "# print(f\"X_train max after scaling: {np.max(X_train)}\")\n",
    "# print(f\"X_train mean after scaling: {np.mean(X_train)}\")\n",
    "# print(f\"X_train std after scaling: {np.std(X_train)}\")\n",
    "\n",
    "# stgcn_model.fit(X_train, y_train, epochs=300, batch_size=64, verbose=1, validation_data=(X_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
